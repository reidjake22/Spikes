# Query: .
# ContextLines: 1

3051 results - 27 files

.gitignore:
    1: .venv/
    2: .DS_Store
    3  # Byte-compiled / optimized / DLL files
    4  __pycache__/
    5: *.py[cod]
    6: *$py.class
    7  
    8  # C extensions
    9: *.so
   10  
   11  # Distribution / packaging
   12: .Python
   13  build/

   17  eggs/
   18: .eggs/
   19  lib/

   25  share/python-wheels/
   26: *.egg-info/
   27: .installed.cfg
   28: *.egg
   29  MANIFEST

   32  #  Usually these files are written by a python script from a template
   33: #  before PyInstaller builds the exe, so as to inject date/other infos into it.
   34: *.manifest
   35: *.spec
   36  
   37  # Installer logs
   38: pip-log.txt
   39: pip-delete-this-directory.txt
   40  

   42  htmlcov/
   43: .tox/
   44: .nox/
   45: .coverage
   46: .coverage.*
   47: .cache
   48: nosetests.xml
   49: coverage.xml
   50: *.cover
   51: *.py,cover
   52: .hypothesis/
   53: .pytest_cache/
   54  cover/

   56  # Translations
   57: *.mo
   58: *.pot
   59  
   60  # Django stuff:
   61: *.log
   62: local_settings.py
   63: db.sqlite3
   64: db.sqlite3-journal
   65  

   67  instance/
   68: .webassets-cache
   69  
   70  # Scrapy stuff:
   71: .scrapy
   72  

   76  # PyBuilder
   77: .pybuilder/
   78  target/

   80  # Jupyter Notebook
   81: .ipynb_checkpoints
   82  

   84  profile_default/
   85: ipython_config.py
   86  

   89  #   intended to run in multiple environments; otherwise, check them in:
   90: # .python-version
   91  
   92  # pipenv
   93: #   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.
   94  #   However, in case of collaboration, if having platform-specific dependencies or dependencies
   95  #   having no cross-platform support, pipenv may install dependencies that don't work, or not
   96: #   install all needed dependencies.
   97: #Pipfile.lock
   98  
   99  # poetry
  100: #   Similar to Pipfile.lock, it is generally recommended to include poetry.lock in version control.
  101  #   This is especially recommended for binary packages to ensure reproducibility, and is more
  102: #   commonly ignored for libraries.
  103: #   https://python-poetry.org/docs/basic-usage/#commit-your-poetrylock-file-to-version-control
  104: #poetry.lock
  105  
  106  # pdm
  107: #   Similar to Pipfile.lock, it is generally recommended to include pdm.lock in version control.
  108: #pdm.lock
  109: #   pdm stores project-wide configurations in .pdm.toml, but it is recommended to not include it
  110: #   in version control.
  111: #   https://pdm.fming.dev/#use-with-ide
  112: .pdm.toml
  113  
  114: # PEP 582; used by e.g. github.com/David-OConnor/pyflow and github.com/pdm-project/pdm
  115  __pypackages__/

  118  celerybeat-schedule
  119: celerybeat.pid
  120  
  121  # SageMath parsed files
  122: *.sage.py
  123  
  124  # Environments
  125: .env
  126: .venv
  127  env/

  129  ENV/
  130: env.bak/
  131: venv.bak/
  132  
  133  # Spyder project settings
  134: .spyderproject
  135: .spyproject
  136  
  137  # Rope project settings
  138: .ropeproject
  139  

  143  # mypy
  144: .mypy_cache/
  145: .dmypy.json
  146: dmypy.json
  147  
  148  # Pyre type checker
  149: .pyre/
  150  
  151  # pytype static type analyzer
  152: .pytype/
  153  

  157  # PyCharm
  158: #  JetBrains specific template is maintained in a separate JetBrains.gitignore that can
  159: #  be found at https://github.com/github/gitignore/blob/main/Global/JetBrains.gitignore
  160: #  and can be added to the global gitignore or merged into this file.  For a more nuclear
  161: #  option (not recommended) you can uncomment the following to ignore the entire idea folder.
  162: #.idea/

LICENCE:
  1: maybe a bit ambitious for now...

NOTES.md:
   2  To activate::
   3: source .venv/bin/activate
   4  To deactivate:

  12      generate the gabor filters according to our specs
  13:     then when you have your data set loaded in as a 3D array convolve each item with the gabor filters.
  14:     The result of each convolved image should be a 3D array, let's store all the images as a 4D array and make this process of convolving a 3D array with the filters to create a 4D array a function. Next I want to take this 4D array of gabor filters and generate a neuron input according to a prespecified mapping between neurons of the layer and the gabor filter. This is using the radius stuff mentioned earlier. Ma
  15  

README.md:
   1: This is a directory to organise my work on spiking neurons.
   2: The goal is to make a cohesive layout of my work, and the modules I build to support it.
   3  

   5  Spikes
   6: ├── .venv
   7  ├── spikes                          # an expanding set of subpackages & modules
   8: │   ├── init.py                     
   9: │   ├── main.py                     # to execute code
  10  │   ├── data                        # for simulation data

  12  │   └── tests                       # to keep code working
  13: │       └── tests.py
  14  ├── docs                            # to document the functionality of the package
  15: │   └── example.rst
  16: ├── README.md
  17: ├── NOTES.md
  18: ├── TODO.md

spikes/main.py:
    1: # this is the main module. I will use this to gate running scripts as I develop. My aim is to develop clear well documented readable code.
    2  

    6  from run import *
    7: from tensorflow.keras.datasets import mnist
    8  

   14      lambdas = [2]  # Wavelengths
   15:     betas = [1.5]  # Scaling factor for bandwidth
   16:     thetas = [0, np.pi / 4, np.pi / 2, 3 * np.pi / 4]  # Orientations
   17:     psis = [0, np.pi]  # Phase offsets
   18:     gammas = [0.5]  # Aspect ratio
   19      size = 128

   22      # Load the MNIST dataset
   23:     (train_images, train_labels), (test_images, test_labels) = mnist.load_data()
   24  

   29      # Normalize the dataset
   30:     dataset = dataset.astype(np.float32) / 255.0
   31      neuron_inputs = generate_inputs_from_filters(

   42  def three_dim_visualise_synapses(synapses: Synapses):
   43:     Ns = len(synapses.source)
   44:     num_pre_neurons = len(synapses.N_incoming_pre)
   45      len_pre = int(sqrt(num_pre_neurons))
   46:     Nt = len(synapses.target)
   47:     num_post_neurons = len(synapses.N_incoming_post)
   48      len_post = int(sqrt(num_post_neurons))
   49:     s_i_column = synapses.i % len_pre
   50:     s_i_row = synapses.i // len_pre
   51:     s_j_column = synapses.j % len_post
   52:     s_j_row = synapses.j // len_post
   53:     fig = plt.figure()
   54:     ax = fig.add_subplot(111, projection="3d")
   55:     ax.scatter(
   56          s_i_column, s_i_row, 0, c="blue", label="Pre-synaptic neurons", s=100
   57      )  # Blue circles
   58:     ax.scatter(
   59          s_j_column, s_j_row, 1, c="red", label="Post-synaptic neurons", s=100

   61      for x1, y1, x2, y2 in zip(x_pre, y_pre, x_post, y_post):
   62:         ax.plot([x1, x2], [y1, y2], [0, 1], "-k", alpha=0.6)  # Black lines with transparency
   63  
   64      for x1, y1, x2, y2 in zip(x_pre, y_pre, x_post, y_post):
   65:         ax.plot([x1, x2], [y1, y2], [0, 1], "-k", alpha=0.6)  # Black lines with transparency
   66  
   67:     plt.show()
   68  

   96          v_reversal_i=-70 * mV,
   97:         sigma=0.015 * mV,
   98          t_refract=2 * ms,  # NEED TO ADD THIS

  114          v_reversal_i=-70 * mV,
  115:         sigma=0.015 * mV,
  116          tau_m=12 * ms,

  122      stdp_synapse_specs = StdpSynapseSpecs(
  123:         lambda_e=0.1 * nS,
  124:         A_minus=0.1,
  125:         A_plus=0.1,
  126:         alpha_C=0.5,
  127:         alpha_D=0.5,
  128          tau_c=3 * ms,

  133      non_stdp_synapse_specs = NonStdpSynapseSpecs(
  134:         lambda_e=0.1 * nS,
  135:         lambda_i=0.1 * nS,
  136      )

  156  
  157:     neuron_inputs.visualise()
  158  

  192      monitors = Monitors(network, n_layers)
  193:     # monitors.setup_monitors([1], "voltage")  # Cant monitor voltage of input layer
  194:     monitors.setup_excitatory_monitors([1], "spike")
  195:     monitors.toggle_monitoring(
  196          [2], "spike", enable=False

  208      print("analysing data")
  209:     monitors.animate_spike_heatmap(
  210:         1, "spike", num_inputs, stimulus_length, exc_neuron_specs.length
  211      )

  221  
  222:     if len(sys.argv) > 1:
  223:         command = sys.argv[1]
  224          if command == "p1":

spikes/test.py:
  14      v_reversal_i=-70 * mV,
  15:     sigma=0.015 * mV,
  16      t_refract=2 * ms,  # NEED TO ADD THIS

  31      v_reversal_i=-70 * mV,
  32:     sigma=0.015 * mV,
  33      tau_m=12 * ms,

  37  stdp_synapse_specs = StdpSynapseSpecs(
  38:     lambda_e=0.1,
  39:     A_minus=0.1,
  40:     A_plus=0.1,
  41:     alpha_C=0.5,
  42:     alpha_D=0.5,
  43      tau_c=3 * ms,

  47  layer = 1
  48: exc_neuron_specs.create_neurons(layer)
  49: inh_neuron_specs.create_neurons(layer)
  50  
  51: stdp_synapse_specs.create_synapses(exc_neuron_specs, inh_neuron_specs, 2, layer)
  52: stdp_synapse_specs.animate_plots(exc_neuron_specs, inh_neuron_specs, 2, layer)

spikes/testing.ipynb:
    9       "data": {
   10:       "application/vnd.jupyter.widget-view+json": {
   11         "model_id": "7705f2b0951a48eaa00410d598d36e16",

   15        "text/plain": [
   16:        "interactive(children=(FloatSlider(value=1.0, description='Scale 1', max=5.0, min=0.1), FloatSlider(value=1.0, …"
   17        ]

   24        "text/plain": [
   25:        "<function __main__.plot_grids(scale1=1.0, scale2=1.0)>"
   26        ]

   34      "import numpy as np\n",
   35:     "import matplotlib.pyplot as plt\n",
   36      "from ipywidgets import interact, FloatSlider\n",

   38      "\n",
   39:     "def plot_grids(scale1=1.0, scale2=1.0):\n",
   40:     "    plt.figure(figsize=(8, 8))\n",
   41:     "    ax = plt.gca()\n",
   42:     "    ax.cla()  # Clear the current figure\n",
   43:     "    ax.set_xlim(-10, 10)\n",
   44:     "    ax.set_ylim(-10, 10)\n",
   45:     "    ax.set_aspect('equal')\n",
   46      "\n",
   47      "    # First grid (blue solid lines)\n",
   48:     "    x1 = np.arange(-10, 10 + scale1, scale1)\n",
   49:     "    y1 = np.arange(-10, 10 + scale1, scale1)\n",
   50      "    for x in x1:\n",
   51:     "        ax.axvline(x, color='blue', linestyle='-', alpha=0.5)\n",
   52      "    for y in y1:\n",
   53:     "        ax.axhline(y, color='blue', linestyle='-', alpha=0.5)\n",
   54      "\n",
   55      "    # Second grid (red dashed lines)\n",
   56:     "    x2 = np.arange(-10, 10 + scale2, scale2)\n",
   57:     "    y2 = np.arange(-10, 10 + scale2, scale2)\n",
   58      "    for x in x2:\n",
   59:     "        ax.axvline(x, color='red', linestyle='--', alpha=0.5)\n",
   60      "    for y in y2:\n",
   61:     "        ax.axhline(y, color='red', linestyle='--', alpha=0.5)\n",
   62      "\n",
   63      "    # Origin point\n",
   64:     "    ax.plot(0, 0, 'ko')  # Black dot at (0,0)\n",
   65      "\n",
   66      "    # Add scale annotations\n",
   67:     "    ax.text(0.05, 0.95, f'Scale1: {scale1}', transform=ax.transAxes, color='blue', fontsize=12, verticalalignment='top')\n",
   68:     "    ax.text(0.05, 0.90, f'Scale2: {scale2}', transform=ax.transAxes, color='red', fontsize=12, verticalalignment='top')\n",
   69      "\n",
   70:     "    ax.grid(False)\n",
   71:     "    plt.show()\n",
   72      "\n",

   74      "interact(plot_grids,\n",
   75:     "         scale1=FloatSlider(min=0.1, max=5.0, step=0.1, value=1.0, description='Scale 1'),\n",
   76:     "         scale2=FloatSlider(min=0.1, max=5.0, step=0.1, value=1.0, description='Scale 2'))"
   77     ]

   85       "data": {
   86:       "application/vnd.jupyter.widget-view+json": {
   87         "model_id": "26da53b07dde439b824527d1304a73d1",

   91        "text/plain": [
   92:        "interactive(children=(FloatSlider(value=1.0, description='Scale 1', max=5.0, min=0.1), FloatSlider(value=1.0, …"
   93        ]

  100        "text/plain": [
  101:        "<function __main__.plot_grids(scale1=1.0, scale2=1.0)>"
  102        ]

  110      "import numpy as np\n",
  111:     "import matplotlib.pyplot as plt\n",
  112      "from ipywidgets import interact, FloatSlider\n",

  114      "\n",
  115:     "def plot_grids(scale1=1.0, scale2=1.0):\n",
  116:     "    plt.figure(figsize=(8, 8))\n",
  117:     "    ax = plt.gca()\n",
  118:     "    ax.cla()  # Clear the current figure\n",
  119:     "    ax.set_xlim(-10, 10)\n",
  120:     "    ax.set_ylim(-10, 10)\n",
  121:     "    ax.set_aspect('equal')\n",
  122      "\n",

  125      "    # Generate grid lines that pass through the origin and extend beyond it\n",
  126:     "    num_lines1 = int(np.ceil(limit / scale1))\n",
  127:     "    x1 = np.arange(-num_lines1 * scale1, (num_lines1 + 1) * scale1, scale1)\n",
  128      "    y1 = x1  # Since it's symmetric\n",
  129      "    for x in x1:\n",
  130:     "        ax.axvline(x, color='blue', linestyle='-', alpha=0.5)\n",
  131      "    for y in y1:\n",
  132:     "        ax.axhline(y, color='blue', linestyle='-', alpha=0.5)\n",
  133      "\n",
  134      "    # Second grid (red dashed lines)\n",
  135:     "    num_lines2 = int(np.ceil(limit / scale2))\n",
  136:     "    x2 = np.arange(-num_lines2 * scale2, (num_lines2 + 1) * scale2, scale2)\n",
  137      "    y2 = x2\n",
  138      "    for x in x2:\n",
  139:     "        ax.axvline(x, color='red', linestyle='--', alpha=0.5)\n",
  140      "    for y in y2:\n",
  141:     "        ax.axhline(y, color='red', linestyle='--', alpha=0.5)\n",
  142      "\n",
  143      "    # Origin point\n",
  144:     "    ax.plot(0, 0, 'ko')  # Black dot at (0,0)\n",
  145      "\n",
  146      "    # Add scale annotations\n",
  147:     "    ax.text(0.05, 0.95, f'Scale1: {scale1}', transform=ax.transAxes, color='blue', fontsize=12, verticalalignment='top')\n",
  148:     "    ax.text(0.05, 0.90, f'Scale2: {scale2}', transform=ax.transAxes, color='red', fontsize=12, verticalalignment='top')\n",
  149      "\n",
  150:     "    ax.grid(False)\n",
  151:     "    plt.show()\n",
  152      "\n",

  154      "interact(plot_grids,\n",
  155:     "         scale1=FloatSlider(min=0.1, max=5.0, step=0.1, value=1.0, description='Scale 1'),\n",
  156:     "         scale2=FloatSlider(min=0.1, max=5.0, step=0.1, value=1.0, description='Scale 2'))"
  157     ]

  167       "text": [
  168:       "WARNING    /Users/jreid/Dropbox/dphil/programming/spikes/spikes/network/neurons.py:151: UserWarning: Parameter tau_ei must be specified (non-None).\n",
  169:       "  warnings.warn(f\"Parameter {name} must be specified (non-None).\")\n",
  170:       " [py.warnings]\n",
  171:       "WARNING    /Users/jreid/Dropbox/dphil/programming/spikes/spikes/network/neurons.py:151: UserWarning: Parameter tau_ii must be specified (non-None).\n",
  172:       "  warnings.warn(f\"Parameter {name} must be specified (non-None).\")\n",
  173:       " [py.warnings]\n",
  174:       "WARNING    /Users/jreid/Dropbox/dphil/programming/spikes/spikes/network/neurons.py:151: UserWarning: Parameter tau_ee must be specified (non-None).\n",
  175:       "  warnings.warn(f\"Parameter {name} must be specified (non-None).\")\n",
  176:       " [py.warnings]\n",
  177:       "WARNING    /Users/jreid/Dropbox/dphil/programming/spikes/spikes/network/neurons.py:151: UserWarning: Parameter tau_ie must be specified (non-None).\n",
  178:       "  warnings.warn(f\"Parameter {name} must be specified (non-None).\")\n",
  179:       " [py.warnings]\n"
  180       ]

  195        "creating E-E synapses for layer 1\n",
  196:       "scale: 1.0\n",
  197:       "size_afferent: 14.0\n",
  198:       "size_efferent: 14.0\n"
  199       ]

  204       "text": [
  205:       "WARNING    Removing unsupported flag '-march=native' from compiler flags. [brian2.codegen.cpp_prefs]\n"
  206       ]

  212        "Setting synapse parameters\n",
  213:       "Setting lambda_e to 100. pS\n",
  214        "Error setting lambda_i: 'SynapseParameters' object has no attribute 'lambda_i'\n",
  215:       "Setting A_minus to 0.1\n",
  216:       "Setting A_plus to 0.1\n",
  217:       "Setting alpha_C to 0.5\n",
  218:       "Setting alpha_D to 0.5\n",
  219:       "Setting tau_c to 3. ms\n",
  220:       "Setting tau_d to 5. ms\n",
  221        "creating E-I synapses for layer 1\n",
  222:       "scale: 2.0\n",
  223:       "size_afferent: 14.0\n",
  224:       "size_efferent: 7.0\n",
  225        "Setting synapse parameters\n",
  226:       "Setting lambda_e to 100. pS\n",
  227:       "Setting lambda_i to 100. pS\n",
  228:       "Error setting lambda_i: Could not find a state variable with name \"lambda_i\". Did you mean to write \"lambda_e\"? Use the add_attribute method if you intend to add a new attribute to the object.\n",
  229        "Error setting A_minus: 'SynapseParameters' object has no attribute 'A_minus'\n",

  235        "creating I-E synapses for layer 1\n",
  236:       "scale: 0.5\n",
  237:       "size_afferent: 7.0\n",
  238:       "size_efferent: 14.0\n",
  239        "Setting synapse parameters\n",
  240:       "Setting lambda_e to 100. pS\n",
  241:       "Error setting lambda_e: Could not find a state variable with name \"lambda_e\". Did you mean to write \"lambda_i\"? Use the add_attribute method if you intend to add a new attribute to the object.\n",
  242:       "Setting lambda_i to 100. pS\n",
  243        "Error setting A_minus: 'SynapseParameters' object has no attribute 'A_minus'\n",

  249        "creating I-I synapses for layer 1\n",
  250:       "scale: 1.0\n",
  251:       "size_afferent: 7.0\n",
  252:       "size_efferent: 7.0\n",
  253        "Setting synapse parameters\n",
  254:       "Setting lambda_e to 100. pS\n",
  255:       "Error setting lambda_e: Could not find a state variable with name \"lambda_e\". Did you mean to write \"lambda_i\"? Use the add_attribute method if you intend to add a new attribute to the object.\n",
  256:       "Setting lambda_i to 100. pS\n",
  257        "Error setting A_minus: 'SynapseParameters' object has no attribute 'A_minus'\n",

  264        "creating E-I synapses for layer 2\n",
  265:       "scale: 2.0\n",
  266:       "size_afferent: 14.0\n",
  267:       "size_efferent: 7.0\n",
  268        "Setting synapse parameters\n",
  269:       "Setting lambda_e to 100. pS\n",
  270:       "Setting lambda_i to 100. pS\n",
  271:       "Error setting lambda_i: Could not find a state variable with name \"lambda_i\". Did you mean to write \"lambda_e\"? Use the add_attribute method if you intend to add a new attribute to the object.\n",
  272        "Error setting A_minus: 'SynapseParameters' object has no attribute 'A_minus'\n",

  278        "creating I-E synapses for layer 2\n",
  279:       "scale: 0.5\n",
  280:       "size_afferent: 7.0\n",
  281:       "size_efferent: 14.0\n",
  282        "Setting synapse parameters\n",
  283:       "Setting lambda_e to 100. pS\n",
  284:       "Error setting lambda_e: Could not find a state variable with name \"lambda_e\". Did you mean to write \"lambda_i\"? Use the add_attribute method if you intend to add a new attribute to the object.\n",
  285:       "Setting lambda_i to 100. pS\n",
  286        "Error setting A_minus: 'SynapseParameters' object has no attribute 'A_minus'\n",

  292        "creating I-I synapses for layer 2\n",
  293:       "scale: 1.0\n",
  294:       "size_afferent: 7.0\n",
  295:       "size_efferent: 7.0\n",
  296        "Setting synapse parameters\n",
  297:       "Setting lambda_e to 100. pS\n",
  298:       "Error setting lambda_e: Could not find a state variable with name \"lambda_e\". Did you mean to write \"lambda_i\"? Use the add_attribute method if you intend to add a new attribute to the object.\n",
  299:       "Setting lambda_i to 100. pS\n",
  300        "Error setting A_minus: 'SynapseParameters' object has no attribute 'A_minus'\n",

  312       "text": [
  313:       "Convolving images: 100%|██████████| 30/30 [00:03<00:00,  9.06it/s]\n",
  314:       "Generating neuron mappings: 100%|██████████| 196/196 [00:01<00:00, 122.42it/s]\n"
  315       ]

  351        "\n",
  352:       "running 1 epochs for a total length of time of 15. s ms\n",
  353        "running epoch no 1\n",
  354:       "current time 0. s\n"
  355       ]

  360       "text": [
  361:       "INFO       No numerical integration method specified for group 'excitatory_layer_1', using method 'euler' (took 0.01s, trying other methods took 0.00s). [brian2.stateupdaters.base.method_choice]\n",
  362:       "INFO       No numerical integration method specified for group 'excitatory_layer_2', using method 'euler' (took 0.00s, trying other methods took 0.00s). [brian2.stateupdaters.base.method_choice]\n",
  363:       "INFO       No numerical integration method specified for group 'inhibitory_layer_1', using method 'euler' (took 0.00s, trying other methods took 0.00s). [brian2.stateupdaters.base.method_choice]\n",
  364:       "INFO       No numerical integration method specified for group 'inhibitory_layer_2', using method 'euler' (took 0.00s, trying other methods took 0.00s). [brian2.stateupdaters.base.method_choice]\n"
  365       ]

  371        "plasticity set to 0 for excitatory_excitatory_1\n",
  372:       "current time 15. s\n",
  373        "Test Complete\n",
  374:       "current time 30. s\n",
  375        "analysing data\n",

  585     "source": [
  586:     "# this is the main module. I will use this to gate running scripts as I develop. My aim is to develop clear well documented readable code.\n",
  587      "\n",

  591      "from run import *\n",
  592:     "from tensorflow.keras.datasets import mnist\n",
  593      "\n",

  598      "    lambdas = [2]  # Wavelengths\n",
  599:     "    betas = [1.5]  # Scaling factor for bandwidth\n",
  600:     "    thetas = [0, np.pi / 4, np.pi / 2, 3 * np.pi / 4]  # Orientations\n",
  601:     "    psis = [0, np.pi]  # Phase offsets\n",
  602:     "    gammas = [0.5]  # Aspect ratio\n",
  603      "    size = 128\n",

  606      "    # Load the MNIST dataset\n",
  607:     "    (train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
  608      "\n",

  613      "    # Normalize the dataset\n",
  614:     "    dataset = dataset.astype(np.float32) / 255.0\n",
  615      "    neuron_inputs = generate_inputs_from_filters(\n",

  626      "def three_dim_visualise_synapses(synapses: Synapses):\n",
  627:     "    Ns = len(synapses.source)\n",
  628:     "    num_pre_neurons = len(synapses.N_incoming_pre)\n",
  629      "    len_pre = int(sqrt(num_pre_neurons))\n",
  630:     "    Nt = len(synapses.target)\n",
  631:     "    num_post_neurons = len(synapses.N_incoming_post)\n",
  632      "    len_post = int(sqrt(num_post_neurons))\n",
  633:     "    s_i_column = synapses.i % len_pre\n",
  634:     "    s_i_row = synapses.i // len_pre\n",
  635:     "    s_j_column = synapses.j % len_post\n",
  636:     "    s_j_row = synapses.j // len_post\n",
  637:     "    fig = plt.figure()\n",
  638:     "    ax = fig.add_subplot(111, projection=\"3d\")\n",
  639:     "    ax.scatter(\n",
  640      "        s_i_column, s_i_row, 0, c=\"blue\", label=\"Pre-synaptic neurons\", s=100\n",
  641      "    )  # Blue circles\n",
  642:     "    ax.scatter(\n",
  643      "        s_j_column, s_j_row, 1, c=\"red\", label=\"Post-synaptic neurons\", s=100\n",

  645      "    for x1, y1, x2, y2 in zip(x_pre, y_pre, x_post, y_post):\n",
  646:     "        ax.plot([x1, x2], [y1, y2], [0, 1], \"-k\", alpha=0.6)  # Black lines with transparency\n",
  647      "\n",
  648      "    for x1, y1, x2, y2 in zip(x_pre, y_pre, x_post, y_post):\n",
  649:     "        ax.plot([x1, x2], [y1, y2], [0, 1], \"-k\", alpha=0.6)  # Black lines with transparency\n",
  650      "\n",
  651:     "    plt.show()\n",
  652      "\n",

  679      "    v_reversal_i=-70 * mV,\n",
  680:     "    sigma=0.015 * mV,\n",
  681      "    t_refract=2 * ms,  # NEED TO ADD THIS\n",

  697      "    v_reversal_i=-70 * mV,\n",
  698:     "    sigma=0.015 * mV,\n",
  699      "    tau_m=12 * ms,\n",

  705      "stdp_synapse_specs = StdpSynapseSpecs(\n",
  706:     "    lambda_e=0.1 * nS,\n",
  707:     "    A_minus=0.1,\n",
  708:     "    A_plus=0.1,\n",
  709:     "    alpha_C=0.5,\n",
  710:     "    alpha_D=0.5,\n",
  711      "    tau_c=3 * ms,\n",

  716      "non_stdp_synapse_specs = NonStdpSynapseSpecs(\n",
  717:     "    lambda_e=0.1 * nS,\n",
  718:     "    lambda_i=0.1 * nS,\n",
  719      ")\n",

  739      "\n",
  740:     "neuron_inputs.visualise()\n",
  741      "\n",

  775      "monitors = Monitors(network, n_layers)\n",
  776:     "# monitors.setup_monitors([1], \"voltage\")  # Cant monitor voltage of input layer\n",
  777:     "monitors.setup_excitatory_monitors([1], \"spike\")\n",
  778:     "monitors.toggle_monitoring(\n",
  779      "    [2], \"spike\", enable=False\n",

  791      "print(\"analysing data\")\n",
  792:     "monitors.animate_spike_heatmap(\n",
  793:     "    1, \"spike\", num_inputs, stimulus_length, exc_neuron_specs.length\n",
  794      ")\n",

  806       "text": [
  807:       "WARNING    /var/folders/kt/dvpckm751r1656f50_b2ptl00000gn/T/ipykernel_27283/3629120997.py:25: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"-k\" (-> color='k'). The keyword argument will take precedence.\n",
  808:       "  ax.plot([x1, x2], [y1, y2], [0, 1], \"-k\", alpha=0.9,color=\"gold\" )  # gold lines with transparency\n",
  809:       " [py.warnings]\n",
  810:       "WARNING    /var/folders/kt/dvpckm751r1656f50_b2ptl00000gn/T/ipykernel_27283/3629120997.py:27: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"-k\" (-> color='k'). The keyword argument will take precedence.\n",
  811:       "  ax.plot([x1, x2], [y1, y2], [0, 1], \"-k\", alpha=0.9,color=\"green\" )\n",
  812:       " [py.warnings]\n"
  813       ]

  816       "data": {
  817:       "application/vnd.jupyter.widget-view+json": {
  818         "model_id": "1241122c122d4430a679b63be8737f11",

  828         "                </div>\n",
  829: ⟪ 361652 characters skipped ⟫AAAAAAAA4NUIWAAAAAAAAPBqBCwAAAAAAAB4NQIWAAAAAAAAvBoBCwAAAAAAAF6NgAUAAAAAAACvRsACAAAAAACAVyNgAQAAAAAAwKsRsAAAAAAAAODVCFgAAAAAAADwagQsAAAAAAAAeDUCFgAAAAAAALza/wcNrA5bGcfWtwAAAABJRU5ErkJggg==' width=1200.0/>\n",
  830         "            </div>\n",

  842      "%matplotlib ipympl\n",
  843:     "synapses = stdp_synapse_specs.synapse_objects[\"excitatory_excitatory_1\"]\n",
  844      "\n",
  845:     "#matplotlib.use('Qt5Agg')  # Or 'TkAgg' if Qt5Agg is unavailablesynapses = stdp_synapse_specs.synapse_objects[\"excitatory_excitatory_1\"]\n",
  846      "def three_dim_visualise_synapses(synapses: Synapses):\n",
  847:     "    Ns = len(synapses.source)\n",
  848:     "    num_pre_neurons = len(synapses.N_outgoing_pre)\n",
  849      "    len_pre = int(sqrt(num_pre_neurons))\n",
  850:     "    Nt = len(synapses.target)\n",
  851:     "    num_post_neurons = len(synapses.N_incoming_post)\n",
  852      "    len_post = int(sqrt(num_post_neurons))\n",
  853:     "    s_i_column = synapses.i % len_pre\n",
  854:     "    s_i_row = synapses.i // len_pre\n",
  855:     "    s_j_column = synapses.j % len_post\n",
  856:     "    s_j_row = synapses.j // len_post\n",
  857:     "    fig = plt.figure(figsize=(12,8))\n",
  858:     "    ax = fig.add_subplot(111, projection=\"3d\")\n",
  859:     "    ax.scatter(\n",
  860      "        s_i_column, s_i_row, 0, c=\"blue\", label=\"Pre-synaptic neurons\", s=100\n",
  861      "    )  # Blue circles\n",
  862:     "    ax.scatter(\n",
  863      "        s_j_column, s_j_row, 1, c=\"red\", label=\"Post-synaptic neurons\", s=100\n",

  866      "        if (x1,y1) == (len_pre//4, len_pre//4):\n",
  867:     "            ax.plot([x1, x2], [y1, y2], [0, 1], \"-k\", alpha=0.9,color=\"gold\" )  # gold lines with transparency\n",
  868      "        elif (x2,y2) == (3* len_pre//4, 3 *len_pre//4):\n",
  869:     "            ax.plot([x1, x2], [y1, y2], [0, 1], \"-k\", alpha=0.9,color=\"green\" )\n",
  870      "        else:\n",
  871:     "            ax.plot([x1, x2], [y1, y2], [0, 1], \"-k\", alpha=0.1)\n",
  872      "    # for x1, y1, x2, y2 in zip(s_i_column, s_i_row, s_j_column, s_j_row):\n",
  873:     "    #     ax.plot([x1, x2], [y1, y2], [0, 1], \"-k\", alpha=0.3)  # Black lines with transparency\n",
  874      "\n",
  875:     "    plt.show(\n",
  876      "    )\n",

  880      "def three_dim_visualise_synapses(synapses: Synapses):\n",
  881:     "    Ns = len(synapses.source)\n",
  882:     "    num_pre_neurons = len(synapses.N_outgoing_pre)\n",
  883      "    len_pre = int(sqrt(num_pre_neurons))\n",
  884:     "    Nt = len(synapses.target)\n",
  885:     "    num_post_neurons = len(synapses.N_incoming_post)\n",
  886      "    len_post = int(sqrt(num_post_neurons))\n",
  887:     "    s_i_column = synapses.i % len_pre\n",
  888:     "    s_i_row = synapses.i // len_pre\n",
  889:     "    s_j_column = synapses.j % len_post\n",
  890:     "    s_j_row = synapses.j // len_post\n",
  891:     "    fig = plt.figure(figsize=(12,8))\n",
  892:     "    ax = fig.add_subplot(111, projection=\"3d\")\n",
  893:     "    ax.scatter(\n",
  894      "        s_i_column, s_i_row, 0, c=\"blue\", label=\"Pre-synaptic neurons\", s=100\n",
  895      "    )  # Blue circles\n",
  896:     "    ax.scatter(\n",
  897      "        s_j_column, s_j_row, 1, c=\"red\", label=\"Post-synaptic neurons\", s=100\n",

  899      "    for x1, y1, x2, y2 in zip(s_i_column, s_i_row, s_j_column, s_j_row):\n",
  900:     "        ax.plot([x1, x2], [y1, y2], [0, 1], \"-k\", alpha=0.1)\n",
  901      "    # for x1, y1, x2, y2 in zip(s_i_column, s_i_row, s_j_column, s_j_row):\n",
  902:     "    #     ax.plot([x1, x2], [y1, y2], [0, 1], \"-k\", alpha=0.3)  # Black lines with transparency\n",
  903      "\n",
  904:     "    plt.show(\n",
  905      "    )\n",

  914     "source": [
  915:     "import matplotlib.pyplot as plt\n",
  916      "from matplotlib import cm\n",

  924      "def three_dim_visualise_synapses(synapses):\n",
  925:     "    Ns = len(synapses.source)\n",
  926:     "    num_pre_neurons = len(synapses.N_outgoing_pre)\n",
  927      "    len_pre = int(sqrt(num_pre_neurons))\n",
  928:     "    Nt = len(synapses.target)\n",
  929:     "    num_post_neurons = len(synapses.N_incoming_post)\n",
  930      "    len_post = int(sqrt(num_post_neurons))\n",

  932      "    # Extract pre- and post-synaptic neuron coordinates\n",
  933:     "    s_i_column = synapses.i % len_pre\n",
  934:     "    s_i_row = synapses.i // len_pre\n",
  935:     "    s_j_column = synapses.j % len_post\n",
  936:     "    s_j_row = synapses.j // len_post\n",
  937      "\n",
  938      "    # Access synapse weights\n",
  939:     "    weights = synapses.w  # Assuming `synapses.w` contains the weights\n",
  940      "\n",
  941      "    # Normalize weights for consistent coloring\n",
  942:     "    weights_normalized = (weights - np.min(weights)) / (np.max(weights) - np.min(weights))\n",
  943      "\n",
  944      "    # Create the figure and axis\n",
  945:     "    fig = plt.figure(figsize=(12, 8))\n",
  946:     "    ax = fig.add_subplot(111, projection=\"3d\")\n",
  947      "\n",
  948      "    # Scatter plot for pre- and post-synaptic neurons\n",
  949:     "    ax.scatter(\n",
  950      "        s_i_column, s_i_row, 0, c=\"blue\", label=\"Pre-synaptic neurons\", s=100\n",
  951      "    )  # Blue circles\n",
  952:     "    ax.scatter(\n",
  953      "        s_j_column, s_j_row, 1, c=\"red\", label=\"Post-synaptic neurons\", s=100\n",

  957      "    for x1, y1, x2, y2, weight in zip(s_i_column, s_i_row, s_j_column, s_j_row, weights_normalized):\n",
  958:     "        color = cm.viridis(weight)  # Map weight to a color using the viridis colormap\n",
  959:     "        ax.plot([x1, x2], [y1, y2], [0, 1], color=color, alpha=0.7)\n",
  960      "\n",
  961      "    # Customize plot\n",
  962:     "    ax.set_xlabel(\"Neuron Grid X\")\n",
  963:     "    ax.set_ylabel(\"Neuron Grid Y\")\n",
  964:     "    ax.set_zlabel(\"Layer (0=Pre, 1=Post)\")\n",
  965:     "    ax.set_title(\"3D Synaptic Connectivity with Weighted Lines\")\n",
  966:     "    ax.legend()\n",
  967      "\n",
  968      "    # Show the plot\n",
  969:     "    plt.show()\n",
  970      "\n",

  977    "kernelspec": {
  978:    "display_name": ".venv",
  979     "language": "python",

  986     },
  987:    "file_extension": ".py",
  988     "mimetype": "text/x-python",

  991     "pygments_lexer": "ipython3",
  992:    "version": "3.12.6"
  993    }

spikes/work_in_progress.ipynb:
    8     "source": [
    9:     "# this is the main module. I will use this to gate running scripts as I develop. My aim is to develop clear well documented readable code.\n",
   10      "from input import *\n",
   11:     "from tensorflow.keras.datasets import mnist    "
   12     ]

   22       "text": [
   23:       "Convolving images: 100%|██████████| 2/2 [00:03<00:00,  1.88s/it]\n",
   24:       "Generating neuron mappings: 100%|██████████| 196/196 [00:04<00:00, 46.14it/s]\n"
   25       ]

   32      "lambdas = [2, 4, 6, 8]  # Wavelengths\n",
   33:     "betas = [1.5]  # Scaling factor for bandwidth\n",
   34:     "thetas = [0, np.pi/4, np.pi/2, 3*np.pi/4]  # Orientations\n",
   35:     "psis = [0, np.pi]  # Phase offsets\n",
   36:     "gammas = [0.5]  # Aspect ratio\n",
   37      "size = 128\n",

   39      "# Load the MNIST dataset\n",
   40:     "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
   41      "\n",

   46      "# Normalize the dataset\n",
   47:     "dataset = dataset.astype(np.float32) / 255.0\n",
   48      "neuron_inputs = generate_inputs_from_filters(dataset,\n",

   65      "poisson groups based on the input profile\n",
   66:     "tracking spikes & voltages.\n",
   67      "\n",
   68:     "I think I'll use clips rather than exponential curves.\n"
   69     ]

   79       "text": [
   80:       "{'Cm': 0.5 * nfarad, 'g_leak': 25. * nsiemens, 'V_rest': -74. * mvolt, 'V_threshold': -53. * mvolt, 'V_reset': -57. * mvolt, 'V_reversal_e': 0. * volt, 'V_reversal_i': -70. * mvolt, 't_refract': 2. * msecond, 'sigma': 15. * uvolt, 'tau_m': 20. * msecond, 'tau_ee': 2. * msecond, 'tau_ie': 2. * msecond}\n",
   81:       "{'Cm': 214. * pfarad, 'g_leak': 28. * nsiemens, 'V_rest': -82. * mvolt, 'V_threshold': -53. * mvolt, 'V_reset': -58. * mvolt, 'V_reversal_e': 0. * volt, 'V_reversal_i': -70. * mvolt, 't_refract': 2. * msecond, 'sigma': 15. * uvolt, 'tau_m': 12. * msecond, 'tau_ei': 5. * msecond, 'tau_ii': 5. * msecond}\n",
   82        "generating input layer\n",

   88      "from brian2 import *\n",
   89:     "from network.neurons import NeuronType\n",
   90      "input_type = NeuronType(\"input\")\n",

   92      "print(\"generating input layer\")\n",
   93:     "first_layer = input_type.create_neuron_layer(size=14)\n",
   94      "print(\"generating inhibitory layer\")\n",
   95:     "first_inhibitory_layer = input_type.create_neuron_layer(size=7)"
   96     ]

  106       "text": [
  107:       "[[1873.31121554  610.12062839 1906.65594093 5837.50297053 2000.69149329\n",
  108:       "  2556.64840686 2651.9995621  2017.29886095 2068.16301787 3380.94495084\n",
  109:       "  2724.6902103  1653.92892916 1685.53282681  910.9837632 ]\n",
  110:       " [1713.59644786 4592.77447499 3226.84347595 1730.55867235 6236.36122085\n",
  111:       "  3395.19482243 3227.0497099  2201.44338951 4627.31274029 1938.56238256\n",
  112:       "  4348.67231533 5170.50934684 1321.35070817 3966.98148126]\n",
  113:       " [2670.80807801 1957.64850443 3947.21034686 2317.79467382 3282.99855135\n",
  114:       "  4872.67169018 3802.77803973 5185.05426387 2329.82386049 3094.97351707\n",
  115:       "  1947.46065554 2762.78488494 2473.42716208 1916.51437364]\n",
  116:       " [2338.31565959 4358.12511025 4218.53848416 4908.68327653 5979.15571548\n",
  117:       "  3988.72926143 5899.92616197 2130.56547895 3195.81410502 5566.82387577\n",
  118:       "  3350.29958292 3872.2536515  3085.2410895  4465.31154623]\n",
  119:       " [4003.81419172 2032.13788264 7080.59908085 4154.16777847 5722.46422432\n",
  120:       "  1552.43657827 4262.76384473 5845.21979644 9811.2409803  3447.10795372\n",
  121:       "  3055.87078568 2478.15008315 5221.9972357  2140.78960989]\n",
  122:       " [3382.91616314 2829.7215841  2938.69535692 2239.42641587 5027.35922607\n",
  123:       "  7634.97043567 6892.92499552 6629.49056803 4013.35723604 2410.23534935\n",
  124:       "  4436.36985971 3024.32148464 1729.94880141 2502.9254937 ]\n",
  125:       " [ 883.09268456 3033.14485547 3403.10376146 2218.44804519 3890.04780162\n",
  126:       "  2166.67668023 2619.34138131 6545.42469566 7633.85952437 4866.47392853\n",
  127:       "  4745.19093218 4123.6630296  3467.54834    3293.70394259]\n",
  128:       " [1987.66838476  715.44883777 1260.26010198 3225.49175575 3048.8948233\n",
  129:       "  2557.49522234 7495.33984441 3548.78739969 7651.64155229 6449.98571647\n",
  130:       "  4133.30091439 3200.27566145 2945.8509189  2461.36964453]\n",
  131:       " [2741.07507515 1873.88006954 2796.3538767   988.48421051 2397.19014828\n",
  132:       "  2503.06280346 4740.43120237 3784.59612585 1805.30649136 6769.13224182\n",
  133:       "  5937.02296444 4484.526425   3303.05149175 2437.0153138 ]\n",
  134:       " [1037.60991114 1485.2700575  2455.38462966 1934.61977436 2116.95112076\n",
  135:       "  6074.50410831 2190.1075738  4026.55211978 6229.62554046 4654.43110796\n",
  136:       "  3191.00463372 4643.89280946 1955.91347275 1755.1875618 ]\n",
  137:       " [2014.12663301 1818.63593083 1130.87057209 1774.72719219 3517.82559014\n",
  138:       "  1467.9037553  4208.12036885 4395.77339909 2014.52852269 4941.57260342\n",
  139:       "  7621.26253216 3535.64503505 1738.62184248 2985.70307831]\n",
  140:       " [4157.78696201 3254.10387262 3616.92141896 2223.59420442  676.6548125\n",
  141:       "  4737.97343292 5436.79347614 1608.89974571 6196.20756454 5095.06248897\n",
  142:       "  1532.24382259 4600.79040832 3803.48935007  741.06711592]\n",
  143:       " [4156.65522903 3345.40073992 3100.14597405 4592.73591332 2987.47697253\n",
  144:       "  2562.18512631 2224.50694978 2622.04020668 5562.84173446 2512.75096178\n",
  145:       "  2841.78905743 1935.72637254 4140.75959204 1729.26160613]\n",
  146:       " [2099.58514879 2846.14059768 4676.75751314 6368.38952597 5385.97705857\n",
  147:       "  1827.11809239 3147.12112214 3367.24642593 2055.05826591 2596.45795844\n",
  148:       "  3005.97048266 1612.7535183  2506.60722127  838.45153588]]\n"
  149       ]

  152     "source": [
  153:     "print(neuron_inputs.input_train[0])"
  154     ]

  164       "text": [
  165:       "WARNING    'i' is an internal variable of group 'synapses_1', but also exists in the run namespace with the value 6. The internal variable will be used. [brian2.groups.group.Group.resolve.resolution_conflict]\n",
  166:       "WARNING    'j' is an internal variable of group 'synapses_1', but also exists in the run namespace with the value 6. The internal variable will be used. [brian2.groups.group.Group.resolve.resolution_conflict]\n",
  167:       "WARNING    The object 'poissongroup' is getting deleted, but was never included in a network. This probably means that you did not store the object reference in a variable, or that the variable was not used to construct the network.\n",
  168        "The object was created here (most recent call only):\n",
  169:       "  File '/var/folders/kt/dvpckm751r1656f50_b2ptl00000gn/T/ipykernel_55868/1481447788.py', line 12, in <module>\n",
  170:       "    poisson_group = PoissonGroup(num_neurons, rates=neuron_inputs_flat * Hz) [brian2.core.base.unused_brian_object]\n",
  171:       "WARNING    The object 'synapses' is getting deleted, but was never included in a network. This probably means that you did not store the object reference in a variable, or that the variable was not used to construct the network.\n",
  172        "The object was created here (most recent call only):\n",
  173:       "  File '/var/folders/kt/dvpckm751r1656f50_b2ptl00000gn/T/ipykernel_55868/1481447788.py', line 32, in <module>\n",
  174:       "    s_input = Synapses(poisson_group, first_layer, on_pre='ge_post += lambda_input') [brian2.core.base.unused_brian_object]\n",
  175:       "WARNING    The object 'neurongroup_1' is getting deleted, but was never included in a network. This probably means that you did not store the object reference in a variable, or that the variable was not used to construct the network.\n",
  176        "The object was created here (most recent call only):\n",
  177:       "  File '/var/folders/kt/dvpckm751r1656f50_b2ptl00000gn/T/ipykernel_55868/3237298363.py', line 14, in <module>\n",
  178:       "    inhib_layer = NeuronGroup(num_inhib_neurons, [brian2.core.base.unused_brian_object]\n"
  179       ]

  190      "# Generate a 14x14 input array (example: random values as input firing rates)\n",
  191:     "neuron_inputs_flat = neuron_inputs.input_train[0].flatten()\n",
  192      "\n",

  203      "# # Assign x and y coordinates to the first layer neurons\n",
  204:     "# first_layer.x = x_coords\n",
  205:     "# first_layer.y = y_coords\n",
  206      "# Manually create x and y coordinates for the PoissonGroup\n",
  207:     "x_coords = np.array([i // grid_size for i in range(num_neurons)])\n",
  208:     "y_coords = np.array([i % grid_size for i in range(num_neurons)])\n",
  209      "\n",

  211      "# Create synaptic connections where the x, y coordinates of both groups match\n",
  212:     "lambda_input = 0.4 * nsiemens\n",
  213      "s_input = Synapses(poisson_group, first_layer, on_pre='ge_post += lambda_input')\n",

  215      "# Now connect neurons where the x, y coordinates match\n",
  216:     "s_input.connect(condition='(i // grid_size == j // grid_size) and (i % grid_size == j % grid_size)')\n"
  217     ]

  234       "text": [
  235:       "WARNING    The object 'synapses_3' is getting deleted, but was never included in a network. This probably means that you did not store the object reference in a variable, or that the variable was not used to construct the network.\n",
  236        "The object was created here (most recent call only):\n",
  237:       "  File '/var/folders/kt/dvpckm751r1656f50_b2ptl00000gn/T/ipykernel_55868/398250973.py', line 38, in <module>\n",
  238:       "    syn_inhib = Synapses(inhib_layer, first_layer, on_pre='ge_post += w_inhib') [brian2.core.base.unused_brian_object]\n",
  239:       "WARNING    The object 'neurongroup_2' is getting deleted, but was never included in a network. This probably means that you did not store the object reference in a variable, or that the variable was not used to construct the network.\n",
  240        "The object was created here (most recent call only):\n",
  241:       "  File '/var/folders/kt/dvpckm751r1656f50_b2ptl00000gn/T/ipykernel_55868/398250973.py', line 19, in <module>\n",
  242:       "    inhib_layer = NeuronGroup(num_inhib_neurons, [brian2.core.base.unused_brian_object]\n"
  243       ]

  246       "ename": "BrianObjectException",
  247:      "evalue": "Error encountered with object named 'neurongroup_3_stateupdater'.\nObject was created here (most recent call only, full details in debug log):\n  File '/Users/jreid/Dropbox/dphil/programming/spikes/spikes/network/neurons.py', line 133, in create_neuron_layer\n    neurons = NeuronGroup(\n\nAn error occurred when preparing an object. (See above for original error message and traceback.)",
  248       "output_type": "error",

  251        "\u001b[0;31mUnsupportedEquationsException\u001b[0m             Traceback (most recent call last)",
  252:       "File \u001b[0;32m~/Dropbox/dphil/programming/spikes/.venv/lib/python3.12/site-packages/brian2/core/network.py:1003\u001b[0m, in \u001b[0;36mNetwork.before_run\u001b[0;34m(self, run_namespace)\u001b[0m\n\u001b[1;32m   1002\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1003\u001b[0m     \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbefore_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_namespace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1004\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
  253:       "File \u001b[0;32m~/Dropbox/dphil/programming/spikes/.venv/lib/python3.12/site-packages/brian2/groups/group.py:1266\u001b[0m, in \u001b[0;36mCodeRunner.before_run\u001b[0;34m(self, run_namespace)\u001b[0m\n\u001b[1;32m   1265\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbefore_run\u001b[39m(\u001b[38;5;28mself\u001b[39m, run_namespace):\n\u001b[0;32m-> 1266\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_code_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_namespace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1267\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mbefore_run(run_namespace)\n",
  254:       "File \u001b[0;32m~/Dropbox/dphil/programming/spikes/.venv/lib/python3.12/site-packages/brian2/groups/group.py:1259\u001b[0m, in \u001b[0;36mCodeRunner.create_code_objects\u001b[0;34m(self, run_namespace)\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_code_objects\u001b[39m(\u001b[38;5;28mself\u001b[39m, run_namespace):\n\u001b[1;32m   1257\u001b[0m     \u001b[38;5;66;03m# By default, we only have one code object for each CodeRunner.\u001b[39;00m\n\u001b[1;32m   1258\u001b[0m     \u001b[38;5;66;03m# Overwrite this function to use more than one.\u001b[39;00m\n\u001b[0;32m-> 1259\u001b[0m     code_object \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_default_code_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_namespace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1260\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m code_object:\n",
  255:       "File \u001b[0;32m~/Dropbox/dphil/programming/spikes/.venv/lib/python3.12/site-packages/brian2/groups/group.py:1230\u001b[0m, in \u001b[0;36mCodeRunner.create_default_code_object\u001b[0;34m(self, run_namespace)\u001b[0m\n\u001b[1;32m   1229\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_default_code_object\u001b[39m(\u001b[38;5;28mself\u001b[39m, run_namespace):\n\u001b[0;32m-> 1230\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_abstract_code\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_namespace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_namespace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1231\u001b[0m     \u001b[38;5;66;03m# If the CodeRunner has variables, add them\u001b[39;00m\n",
  256:       "File \u001b[0;32m~/Dropbox/dphil/programming/spikes/.venv/lib/python3.12/site-packages/brian2/groups/neurongroup.py:287\u001b[0m, in \u001b[0;36mStateUpdater.update_abstract_code\u001b[0;34m(self, run_namespace)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroup\u001b[38;5;241m.\u001b[39mequations\u001b[38;5;241m.\u001b[39mdiff_eq_names) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 287\u001b[0m     stateupdate_output \u001b[38;5;241m=\u001b[39m \u001b[43mStateUpdateMethod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_stateupdater\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mequations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(stateupdate_output, \u001b[38;5;28mstr\u001b[39m):\n",
  257:       "File \u001b[0;32m~/Dropbox/dphil/programming/spikes/.venv/lib/python3.12/site-packages/brian2/utils/caching.py:107\u001b[0m, in \u001b[0;36mcached.<locals>.cached_func\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    106\u001b[0m     func\u001b[38;5;241m.\u001b[39m_cache_statistics\u001b[38;5;241m.\u001b[39mmisses \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 107\u001b[0m     func\u001b[38;5;241m.\u001b[39m_cache[cache_key] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func\u001b[38;5;241m.\u001b[39m_cache[cache_key]\n",
  258:       "File \u001b[0;32m~/Dropbox/dphil/programming/spikes/.venv/lib/python3.12/site-packages/brian2/stateupdaters/base.py:246\u001b[0m, in \u001b[0;36mStateUpdateMethod.apply_stateupdater\u001b[0;34m(equations, variables, method, method_options, group_name)\u001b[0m\n\u001b[1;32m    245\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 246\u001b[0m code \u001b[38;5;241m=\u001b[39m \u001b[43mstateupdater\u001b[49m\u001b[43m(\u001b[49m\u001b[43mequations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    247\u001b[0m method_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
  259:       "File \u001b[0;32m~/Dropbox/dphil/programming/spikes/.venv/lib/python3.12/site-packages/brian2/utils/caching.py:107\u001b[0m, in \u001b[0;36mcached.<locals>.cached_func\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    106\u001b[0m     func\u001b[38;5;241m.\u001b[39m_cache_statistics\u001b[38;5;241m.\u001b[39mmisses \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 107\u001b[0m     func\u001b[38;5;241m.\u001b[39m_cache[cache_key] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func\u001b[38;5;241m.\u001b[39m_cache[cache_key]\n",
  260:       "File \u001b[0;32m~/Dropbox/dphil/programming/spikes/.venv/lib/python3.12/site-packages/brian2/stateupdaters/exact.py:177\u001b[0m, in \u001b[0;36mLinearStateUpdater.__call__\u001b[0;34m(self, equations, variables, method_options)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m equations\u001b[38;5;241m.\u001b[39mis_stochastic:\n\u001b[0;32m--> 177\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnsupportedEquationsException(\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot solve stochastic equations with this state updater.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    179\u001b[0m     )\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m variables \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
  261:       "\u001b[0;31mUnsupportedEquationsException\u001b[0m: Cannot solve stochastic equations with this state updater.",
  262        "\nThe above exception was the direct cause of the following exception:\n",

  264        "Cell \u001b[0;32mIn[19], line 59\u001b[0m\n\u001b[1;32m     56\u001b[0m spike_mon_inhib \u001b[38;5;241m=\u001b[39m SpikeMonitor(inhib_layer)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# Run the simulation\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Print spike times to check the simulation\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMain layer spikes:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
  265:       "File \u001b[0;32m~/Dropbox/dphil/programming/spikes/.venv/lib/python3.12/site-packages/brian2/units/fundamentalunits.py:2652\u001b[0m, in \u001b[0;36mcheck_units.<locals>.do_check_units.<locals>.new_f\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m   2642\u001b[0m             error_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2643\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2644\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected a quantity with unit \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2645\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00munit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for argument \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m but got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2646\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2647\u001b[0m ⟪ 1096 characters skipped ⟫] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   2655\u001b[0m         \u001b[38;5;28mbool\u001b[39m,\n\u001b[1;32m   2656\u001b[0m         np\u001b[38;5;241m.\u001b[39mbool_,\n\u001b[1;32m   2657\u001b[0m     ):\n",
  266:       "File \u001b[0;32m~/Dropbox/dphil/programming/spikes/.venv/lib/python3.12/site-packages/brian2/core/magic.py:407\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(duration, report, report_period, namespace, profile, level)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;129m@check_units\u001b[39m(duration\u001b[38;5;241m=\u001b[39msecond, report_period\u001b[38;5;241m=\u001b[39msecond)\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\n\u001b[1;32m    336\u001b[0m     duration,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    341\u001b[0m     level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m    342\u001b[0m ):\n\u001b[1;32m    343\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;124;03m    run(duration, report=None, report_period=10*second, namespace=None, level=0)\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;124;03m        intended use. See `MagicNetwork` for more details.\u001b[39;00m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 407\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmagic_network\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreport_period\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreport_period\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnamespace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprofile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u
  267:       "File \u001b[0;32m~/Dropbox/dphil/programming/spikes/.venv/lib/python3.12/site-packages/brian2/core/magic.py:248\u001b[0m, in \u001b[0;36mMagicNetwork.run\u001b[0;34m(self, duration, report, report_period, namespace, profile, level)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    240\u001b[0m     duration,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    245\u001b[0m     level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m    246\u001b[0m ):\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_magic_objects(level\u001b[38;5;241m=\u001b[39mlevel \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 248\u001b[0m     \u001b[43mNetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreport_period\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreport_period\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnamespace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprofile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b
  268:       "File \u001b[0;32m~/Dropbox/dphil/programming/spikes/.venv/lib/python3.12/site-packages/brian2/core/base.py:346\u001b[0m, in \u001b[0;36mdevice_override.<locals>.device_override_decorator.<locals>.device_override_decorated_function\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(curdev, name)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
  269:       "File \u001b[0;32m~/Dropbox/dphil/programming/spikes/.venv/lib/python3.12/site-packages/brian2/units/fundamentalunits.py:2652\u001b[0m, in \u001b[0;36mcheck_units.<locals>.do_check_units.<locals>.new_f\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m   2642\u001b[0m             error_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2643\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2644\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected a quantity with unit \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2645\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00munit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for argument \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m but got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2646\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2647\u001b[0m ⟪ 1096 characters skipped ⟫] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   2655\u001b[0m         \u001b[38;5;28mbool\u001b[39m,\n\u001b[1;32m   2656\u001b[0m         np\u001b[38;5;241m.\u001b[39mbool_,\n\u001b[1;32m   2657\u001b[0m     ):\n",
  270:       "File \u001b[0;32m~/Dropbox/dphil/programming/spikes/.venv/lib/python3.12/site-packages/brian2/core/network.py:1141\u001b[0m, in \u001b[0;36mNetwork.run\u001b[0;34m(self, duration, report, report_period, namespace, profile, level)\u001b[0m\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m namespace \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1139\u001b[0m     namespace \u001b[38;5;241m=\u001b[39m get_local_namespace(level\u001b[38;5;241m=\u001b[39mlevel \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m-> 1141\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbefore_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(all_objects) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m  \u001b[38;5;66;03m# TODO: raise an error? warning?\u001b[39;00m\n",
  271:       "File \u001b[0;32m~/Dropbox/dphil/programming/spikes/.venv/lib/python3.12/site-packages/brian2/core/base.py:346\u001b[0m, in \u001b[0;36mdevice_override.<locals>.device_override_decorator.<locals>.device_override_decorated_function\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(curdev, name)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
  272:       "File \u001b[0;32m~/Dropbox/dphil/programming/spikes/.venv/lib/python3.12/site-packages/brian2/core/network.py:1005\u001b[0m, in \u001b[0;36mNetwork.before_run\u001b[0;34m(self, run_namespace)\u001b[0m\n\u001b[1;32m   1003\u001b[0m             obj\u001b[38;5;241m.\u001b[39mbefore_run(run_namespace)\n\u001b[1;32m   1004\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[0;32m-> 1005\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m BrianObjectException(\n\u001b[1;32m   1006\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred when preparing an object.\u001b[39m\u001b[38;5;124m\"\u001b[39m, obj\n\u001b[1;32m   1007\u001b[0m             ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mex\u001b[39;00m\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;66;03m# Check that no object has been run as part of another network before\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m all_objects:\n",
  273:       "\u001b[0;31mBrianObjectException\u001b[0m: Error encountered with object named 'neurongroup_3_stateupdater'.\nObject was created here (most recent call only, full details in debug log):\n  File '/Users/jreid/Dropbox/dphil/programming/spikes/spikes/network/neurons.py', line 133, in create_neuron_layer\n    neurons = NeuronGroup(\n\nAn error occurred when preparing an object. (See above for original error message and traceback.)"
  274       ]

  285      "# Generate a 14x14 input array (example: random values as input firing rates)\n",
  286:     "np.random.seed(42)  # For reproducibility\n",
  287:     "neuron_inputs_flat = np.random.rand(num_neurons) * 20  # Random firing rates between 0 and 20 Hz\n",
  288      "\n",

  298      "# Assign x and y coordinates to the inhibitory layer neurons\n",
  299:     "x_coords_inhib = np.array([i // inhib_size for i in range(num_inhib_neurons)])\n",
  300:     "y_coords_inhib = np.array([i % inhib_size for i in range(num_inhib_neurons)])\n",
  301:     "inhib_layer.x = x_coords_inhib\n",
  302:     "inhib_layer.y = y_coords_inhib\n",
  303      "\n",

  305      "# connects to a fan-out set of neurons in the main layer based on distance\n",
  306:     "w_inhib = 0.4 * nsiemens  # Weight of the inhibitory synapse\n",
  307      "\n",

  320      "                # Calculate the distance between the center and each neuron in the main layer\n",
  321:     "                dist = np.sqrt((center_x - m) ** 2 + (center_y - n) ** 2)\n",
  322      "                \n",

  328      "                    # Connect the inhibitory neuron to the corresponding main layer neurons\n",
  329:     "                    syn_inhib.connect(i=inhib_idx, j=main_idx)\n",
  330      "\n",

  339      "print(\"Main layer spikes:\")\n",
  340:     "print(spike_mon_main.spike_trains())\n",
  341      "\n",
  342      "print(\"\\nInhibitory layer spikes:\")\n",
  343:     "print(spike_mon_inhib.spike_trains())"
  344     ]

  377      "        model = \"\"\"\n",
  378:     "            dv/dt = (V_rest-v)/tau_m + (ge*(V_reversal_e-v) + gi*(V_reversal_i-v))/(tau_m*g_leak) + sigma*xi*(tau_m)**-0.5 : volt\n",
  379      "            dge/dt = -ge/tau_ee : siemens\n",

  402      "            \"t_refract\": 2 * ms,  # Refractory period\n",
  403:     "            \"sigma\": 0.015 * mV,  # Noise intensity\n",
  404      "            \"tau_m\": 12 * ms,  # Membrane time constant\n",

  423       "text": [
  424:       "NeuronParameters(membrane_potential=-60. * mvolt, threshold=-50. * mvolt, resting_potential=-65. * mvolt, refractory_period=5. * msecond, time_constant=10. * msecond)\n"
  425       ]

  448    "kernelspec": {
  449:    "display_name": ".venv",
  450     "language": "python",

  457     },
  458:    "file_extension": ".py",
  459     "mimetype": "text/x-python",

  462     "pygments_lexer": "ipython3",
  463:    "version": "3.12.6"
  464    }

spikes/archived/controller.py:
  28  stdp_synapse_specs = StdpSynapseSpecs(
  29:     lambda_e=0.1,
  30:     A_minus=0.1,
  31:     A_plus=0.1,
  32:     alpha_C=0.1,
  33:     alpha_D=0.1,
  34:     tau_pre=0.1,
  35:     tau_post=0.1,
  36  )

  39  non_stdp_synapse_specs = NonStdpSynapseSpecs(
  40:     lambda_e=0.1,
  41:     lambda_i=0.1,
  42  )

  45  input_synapse_specs = InputSynapseSpecs(
  46:     lambda_e=0.1,
  47  )

  60  )
  61: inputs = np.array([0])
  62  poisson_neurons = generate_inputs(inputs)

spikes/archived/filter_archive.py:
    5  import random 
    6: from scipy.signal import convolve2d
    7  

   12      def __init__(self, input_train, mapping):
   13:         self.input_train = input_train
   14:         self.mapping = mapping
   15  

   17      """
   18:     Class representing a single Gabor filter. Responsible for generating, 
   19:     manipulating, and saving the Gabor filter based on the input parameters.
   20      """

   23          """
   24:         Initialize a GaborFilter object with specific parameters.
   25  
   26          Args:
   27:         size (int): Size of the square filter.
   28:         lambda_ (float): Wavelength of the sinusoidal factor.
   29:         beta (float): Scaling factor controlling bandwidth.
   30:         theta (float): Orientation of the Gabor filter in radians.
   31:         psi (float): Phase offset of the sinusoidal factor.
   32:         gamma (float): Aspect ratio of the Gaussian envelope.
   33          """
   34:         self.size = size
   35:         self.lambda_ = lambda_
   36:         self.beta = beta
   37:         self.theta = theta
   38:         self.psi = psi
   39:         self.gamma = gamma
   40:         self.filter_array = self._generate_filter()
   41  

   43          """
   44:         Generate the meshgrid (x, y coordinates) for the Gabor filter based on size.
   45  
   46          Returns:
   47:         x, y (ndarray): Two 2D arrays representing the coordinates.
   48          """
   49:         x = np.linspace(-self.size // 2, self.size // 2 - 1, self.size)
   50:         y = np.linspace(-self.size // 2, self.size // 2 - 1, self.size)
   51:         return np.meshgrid(x, y)
   52  

   54          """
   55:         Generate the Gabor filter based on the object's parameters.
   56  
   57          Returns:
   58:         filter_array (ndarray): The 2D Gabor filter.
   59          """
   60:         x, y = self._generate_meshgrid()
   61          # Apply rotation to coordinates
   62:         x_prime = x * np.cos(self.theta) + y * np.sin(self.theta)
   63:         y_prime = -x * np.sin(self.theta) + y * np.cos(self.theta)
   64          
   65          # Compute sigma (standard deviation) for the Gaussian component
   66:         sigma = (self.lambda_ * (2**self.beta + 1)) / (np.pi * (2**self.beta - 1))
   67  
   68          # Calculate the exponential (Gaussian) and cosine (sinusoidal) components
   69:         exp_component = np.exp(-(x_prime**2 + self.gamma**2 * y_prime**2) / (2 * sigma**2))
   70:         cos_component = np.cos(2 * np.pi * x_prime / self.lambda_ + self.psi)
   71          

   75          """
   76:         Save the Gabor filter as a PNG image.
   77  
   78          Args:
   79:         directory (str): Directory where the image will be saved.
   80          """
   81:         filename = f"gabor_l{self.lambda_}_b{self.beta}_t{self.theta:.2f}_p{self.psi:.2f}_g{self.gamma}.png"
   82:         filepath = os.path.join(directory, filename)
   83  
   84          # Normalize the filter values to the range [0, 255] for image saving
   85:         normalized_filter = 255 * (self.filter_array - np.min(self.filter_array)) / (np.max(self.filter_array) - np.min(self.filter_array))
   86:         image = Image.fromarray(normalized_filter.astype(np.uint8))
   87:         image.save(filepath)
   88          print(f"Saved image to {filepath}")

   91          """
   92:         Save the Gabor filter as a NumPy array file (.npy).
   93  
   94          Args:
   95:         directory (str): Directory where the NumPy file will be saved.
   96          """
   97:         filename = f"gabor_l{self.lambda_}_b{self.beta}_t{self.theta:.2f}_p{self.psi:.2f}_g{self.gamma}.npy"
   98:         filepath = os.path.join(directory, filename)
   99:         np.save(filepath, self.filter_array)
  100          print(f"Saved NumPy array to {filepath}")

  104      Class responsible for generating, storing, and managing multiple Gabor filters 
  105:     based on various combinations of parameters.
  106      """

  110          Initialize the GaborFilters object by generating and storing GaborFilter objects 
  111:         for each combination of input parameters.
  112  
  113          Args:
  114:         size (int): Size of the square Gabor filters.
  115:         lambdas (list of floats): List of wavelengths for the filters.
  116:         betas (list of floats): List of scaling factors controlling bandwidth.
  117:         thetas (list of floats): List of orientations (angles) in radians.
  118:         psis (list of floats): List of phase offsets.
  119:         gammas (list of floats): List of aspect ratios.
  120          """
  121:         self.size = size
  122:         self.lambdas = lambdas
  123:         self.betas = betas
  124:         self.thetas = thetas
  125:         self.psis = psis
  126:         self.gammas = gammas
  127:         self.filters = []  # Store GaborFilter objects in a list
  128:         self._generate_all_filters()
  129  

  131          """
  132:         Generate all possible Gabor filters based on the provided parameter lists.
  133:         Each unique combination of parameters is used to create a GaborFilter object.
  134          """
  135:         # Use itertools.product to get every combination of the parameter values
  136:         for lambda_, beta, theta, psi, gamma in product(self.lambdas, self.betas, self.thetas, self.psis, self.gammas):
  137              # Create a new GaborFilter instance for each parameter combination
  138:             gabor_filter = GaborFilter(self.size, lambda_, beta, theta, psi, gamma)
  139:             self.filters.append(gabor_filter)
  140  

  142          """
  143:         Retrieve a specific GaborFilter object based on its parameters.
  144  
  145          Args:
  146:         lambda_ (float): Wavelength of the desired filter.
  147:         beta (float): Scaling factor controlling bandwidth.
  148:         theta (float): Orientation of the desired filter in radians.
  149:         psi (float): Phase offset of the desired filter.
  150:         gamma (float): Aspect ratio of the desired filter.
  151  
  152          Returns:
  153:         GaborFilter: The Gabor filter object that matches the input parameters.
  154  
  155          Raises:
  156:         ValueError: If no filter is found with the specified parameters.
  157          """
  158          # Search the filters list for a GaborFilter object with matching parameters
  159:         for gabor_filter in self.filters:
  160:             if (gabor_filter.lambda_ == lambda_ and gabor_filter.beta == beta and 
  161:                 gabor_filter.theta == theta and gabor_filter.psi == psi and 
  162:                 gabor_filter.gamma == gamma):
  163                  return gabor_filter
  164          # Raise an error if no matching filter is found
  165:         raise ValueError(f"Gabor filter with parameters lambda={lambda_}, beta={beta}, theta={theta}, psi={psi}, gamma={gamma} not found.")
  166  

  168          """
  169:         Save all stored Gabor filters as PNG images in the specified directory.
  170  
  171          Args:
  172:         directory (str): Directory where the images will be saved.
  173          """
  174:         for gabor_filter in self.filters:
  175:             gabor_filter.save_as_image(directory)
  176  

  178          """
  179:         Save all stored Gabor filters as NumPy array files (.npy) in the specified directory.
  180  
  181          Args:
  182:         directory (str): Directory where the NumPy files will be saved.
  183          """
  184:         for gabor_filter in self.filters:
  185:             gabor_filter.save_as_numpy(directory)
  186  

  188      """
  189:     Class representing a single convolution layer.
  190      It stores the result of convolving an image with a Gabor filter,
  191:     and keeps track of the GaborFilter used for the convolution.
  192      """

  195          """
  196:         Initialize the ConvLayer with a GaborFilter object and the convolution result.
  197  
  198          Args:
  199:         gabor_filter (GaborFilter): The GaborFilter used for the convolution.
  200:         conv_result (ndarray): The result of convolving the image with the Gabor filter.
  201          """
  202:         self.gabor_filter = gabor_filter  # Store the GaborFilter used
  203:         self.conv_result = conv_result    # Store the convolution result
  204  

  206          """
  207:         Save the convolution result as a PNG image.
  208  
  209          Args:
  210:         directory (str): Directory where the image will be saved.
  211          """
  212:         filename = f"conv_l{self.gabor_filter.lambda_}_b{self.gabor_filter.beta}_t{self.gabor_filter.theta:.2f}_p{self.gabor_filter.psi:.2f}_g{self.gabor_filter.gamma}.png"
  213:         filepath = os.path.join(directory, filename)
  214  
  215          # Normalize the convolution result to [0, 255] for saving as an image
  216:         normalized_result = 255 * (self.conv_result - np.min(self.conv_result)) / (np.max(self.conv_result) - np.min(self.conv_result))
  217:         image = Image.fromarray(normalized_result.astype(np.uint8))
  218:         image.save(filepath)
  219          print(f"Saved convolution result to {filepath}")

  222      """
  223:     Class representing a collection of convolution layers.
  224      It stores multiple ConvLayer objects, each representing the result
  225:     of convolving an image with a different Gabor filter.
  226:     On initialization, all ConvLayer objects are created using the input image and GaborFilters.
  227      """

  230          """
  231:         Initialize the ConvImage by performing convolutions of the input image with each GaborFilter.
  232  
  233          Args:
  234:         gabor_filters (GaborFilters): The GaborFilters object containing multiple Gabor filters.
  235:         image (ndarray): The input image to be convolved with each Gabor filter.
  236          """
  237:         self.image = image          # Store the input image
  238:         self.gabor_filters = gabor_filters  # Store the GaborFilters object
  239:         self.layers = []            # List to store ConvLayer objects
  240          
  241:         self._create_conv_layers()  # Automatically create ConvLayer objects
  242  

  244          """
  245:         Create a ConvLayer for each Gabor filter by convolving the filter with the input image.
  246          """
  247          # Loop through all Gabor filters in the GaborFilters object
  248:         for gabor_filter in self.gabor_filters.filters:
  249              # Perform the 2D convolution between the image and the Gabor filter
  250:             conv_result = convolve2d(self.image, gabor_filter.filter_array, mode='same', boundary='wrap')
  251  

  255              # Add the ConvLayer to the list of layers
  256:             self.layers.append(conv_layer)
  257  

  259          """
  260:         Save all convolution results (layers) as images in the specified directory.
  261  
  262          Args:
  263:         directory (str): Directory where the images will be saved.
  264          """
  265:         for layer in self.layers:
  266:             layer.save_as_image(directory)
  267  

  269          """
  270:         Retrieve a ConvLayer by the parameters of the Gabor filter used.
  271  
  272          Args:
  273:         lambda_ (float): Wavelength of the desired Gabor filter.
  274:         beta (float): Scaling factor controlling bandwidth.
  275:         theta (float): Orientation of the desired filter in radians.
  276:         psi (float): Phase offset of the desired filter.
  277:         gamma (float): Aspect ratio of the desired filter.
  278  
  279          Returns:
  280:         ConvLayer: The ConvLayer object corresponding to the Gabor filter with the specified parameters.
  281  
  282          Raises:
  283:         ValueError: If no matching ConvLayer is found.
  284          """
  285          # Iterate through the list of ConvLayer objects
  286:         for layer in self.layers:
  287:             gabor_filter = layer.gabor_filter
  288              # Check if the Gabor filter parameters match the desired parameters
  289:             if (gabor_filter.lambda_ == lambda_ and
  290:                 gabor_filter.beta == beta and
  291:                 gabor_filter.theta == theta and
  292:                 gabor_filter.psi == psi and
  293:                 gabor_filter.gamma == gamma):
  294                  return layer

  300      """
  301:     Convolve each image in a dataset with a set of Gabor filters and return a 4D array.
  302      This is the crux of it - what we do with this convolved set is combined it with the mapping
  303      Args:
  304:     dataset (ndarray): 3D array of images with shape (num_images, height, width).
  305:     gabor_filters (GaborFilters): GaborFilters object containing multiple filters.
  306  
  307      Returns:
  308:     4D ndarray: Convolved results with shape (num_images, height, width, num_filters).
  309      """
  310:     num_images, image_height, image_width = dataset.shape
  311:     num_filters = len(gabor_filters.filters)
  312  
  313      # Initialize the 4D array to store convolved images
  314:     convolved_results = np.zeros((num_images, image_height, image_width, num_filters))
  315  

  318          # Loop over each Gabor filter
  319:         for filter_idx, gabor_filter in enumerate(gabor_filters.filters):
  320              # Convolve the image with the current Gabor filter
  321:             convolved_image = convolve2d(image, gabor_filter.filter_array, mode='same', boundary='wrap')
  322              # Store the convolved image in the 4D array

  328      def __init__(self, mapping=None, image_size=None, neuron_size=None, num_layers=None, num_total_pixels=None, radius=None, shape=None):
  329:         self.image_size = image_size
  330:         self.neuron_size = neuron_size
  331:         self.num_layers = num_layers
  332:         self.num_total_pixels = num_total_pixels
  333:         self.radius = radius
  334:         self.shape = shape
  335:         self.mapping = self.gen_mappings(image_size, neuron_size, num_layers, num_total_pixels, radius, shape)
  336          

  339          Generate a pixel mapping for neurons where each neuron is mapped to a subset of 3D pixels
  340:         (x, y, layer) from an image, within a radius around its corresponding position. The region can be 
  341:         either circular or square.
  342  
  343          Args:
  344:         image_size (int): The size of the image (assumed square).
  345:         neuron_size (int): The size of the neuron array (assumed square).
  346:         num_layers (int): The number of layers in the convolved image stack (number of filters).
  347:         num_total_pixels (int): The total number of unique pixels to sample across layers (default: 100).
  348:         radius (int): The radius around the neuron center in the image (default: 6).
  349:         shape (str): The shape of the eligible region, either "circle" or "square" (default: "circle").
  350  

  352          dict: A dictionary where each key is a (neuron_x, neuron_y) tuple and the value is
  353:                 a list of randomly selected (x, y, layer) coordinates.
  354          """

  376                              # Compute the Euclidean distance from the center
  377:                             distance = np.sqrt((x - x_center) ** 2 + (y - y_center) ** 2)
  378                              # Only include pixels within the circular radius
  379                              if distance <= radius:
  380:                                 region_pixels.append((x, y))
  381                          elif shape == "square":
  382                              # Include all pixels within the bounding box for a square
  383:                             region_pixels.append((x, y))
  384                  

  389                  if num_total_pixels > available_pixels:
  390:                     print(f"Warning: Requested {num_total_pixels} pixels, but only {available_pixels} available for neuron ({neuron_x}, {neuron_y}).")
  391                      num_samples = available_pixels  # Limit the number of samples to the available pixels

  401                  # Randomly sample num_samples 3D coordinates without replacement
  402:                 selected_pixels = random.sample(all_3d_coords, num_samples)
  403  

  410          """
  411:         Generate neuron inputs from a 4D convolved dataset using precomputed 3D pixel mappings.
  412  
  413          Args:
  414:         convolved_data (ndarray): 4D array of convolved images with shape (num_images, height, width, num_filters).
  415          pixel_mappings (obj): ImageMapping object - contains the correct 
  416:         neuron_size (int): The size of the neuron array (e.g., 14 for a 14x14 neuron grid).
  417  
  418          Returns:
  419:         3D ndarray: Neuron inputs with shape (num_images, neuron_size, neuron_size).
  420          """
  421:         num_images, image_height, image_width, num_filters = convolved_data.shape
  422:         neuron_size = self.neuron_size
  423:         image_mapping = self.mapping
  424          # Initialize the 3D array to store neuron inputs (num_images, neuron_size, neuron_size)
  425:         neuron_inputs = np.zeros((num_images, neuron_size, neuron_size))
  426  

  429              # Loop over each neuron
  430:             for (neuron_x, neuron_y) in image_mapping.keys():
  431                  # Get the precomputed 3D pixel mappings for this neuron

  436                  for layer, x, y in selected_pixels:
  437:                     input_values.append(convolved_data[image_idx, x, y, layer])
  438  
  439                  # Average the input values to assign to the neuron
  440:                 neuron_inputs[image_idx, neuron_x, neuron_y] = np.mean(input_values)
  441  

  445      """
  446:     Generate neuron inputs for a dataset by convolving images with Gabor filters and mapping pixels to neurons.
  447  
  448      Args:
  449:     dataset (ndarray): 3D array of images with shape (num_images, height, width).
  450:     gabor_filters (GaborFilters): GaborFilters object containing multiple filters.
  451:     neuron_size (int): Size of the neuron grid (e.g., 14 for 14x14 neurons).
  452:     image_size (int): Size of the input images (e.g., 28x28).
  453:     num_total_pixels (int): Number of pixels to sample for each neuron.
  454:     radius (int): Radius around the center of the pixel region for each neuron.
  455:     shape (str): Shape of the region ("circle" or "square").
  456  
  457      Returns:
  458:     3D ndarray: Neuron inputs with shape (num_images, neuron_size, neuron_size).
  459      """

  463      # Step 2: Generate pixel mappings from the image space to the neuron grid
  464:     num_layers = len(gabor_filters.filters)
  465      image_mapping = ImageMapping(image_size, neuron_size, num_layers, num_total_pixels, radius, shape)

  467      # Step 3: Generate neuron inputs using the 3D pixel mappings
  468:     neuron_train = image_mapping.gen_inputs(convolved_data)
  469      neuron_inputs = NeuronInputs(neuron_train, image_mapping)

spikes/archived/neurons.py:
   14          """
   15:         Initializes the neuron model based on the provided neuron type (excitatory, inhibitory, or input).
   16  
   17          Args:
   18:         neuron_type: Type of neuron model ("excitatory", "inhibitory", or "input"). Default is "excitatory".
   19:         params: Dictionary of custom neuron parameters. If None, default parameters are used.
   20          """

   23              "excitatory": """
   24:             dv/dt = (V_rest-v)/tau_m + (ge*(V_reversal_e-v) + gi*(V_reversal_i-v))/(tau_m*g_leak) + sigma*xi*(tau_m)**-0.5 : volt
   25              dge/dt = -ge/tau_ee : siemens

   39              "inhibitory": """
   40:             dv/dt = (V_rest-v)/tau_m + (ge*(V_reversal_e-v) + gi*(V_reversal_i-v))/(tau_m * g_leak) + sigma*xi*(tau_m)**-0.5 : volt
   41              dge/dt = -ge/tau_ei : siemens

   53              "input": """
   54:             dv/dt = (V_rest-v)/tau_m + (ge*(V_reversal_e-v) + gi*(V_reversal_i-v))/(tau_m*g_leak) + sigma*xi*(tau_m)**-0.5 : volt
   55              dge/dt = -ge/tau_ee : siemens

   80              "t_refract": 2 * ms,  # Refractory period after spike
   81:             "sigma": 0.015 * mV,  # Noise intensity
   82              "tau_m": 20 * ms,  # Membrane time constant

   97              "t_refract": 2 * ms,  # Refractory period
   98:             "sigma": 0.015 * mV,  # Noise intensity
   99              "tau_m": 12 * ms,  # Membrane time constant

  105  
  106:         self.neuron_type = neuron_type  # Store the neuron type
  107  
  108          # Select default parameters based on neuron type
  109:         if self.neuron_type == "excitatory" or self.neuron_type == "input":
  110              default_params = default_params_excitatory

  115          if params is not None:
  116:             self.params = {
  117                  **default_params,

  120          else:
  121:             self.params = default_params
  122  
  123:         print(self.params)
  124  
  125          # Select the appropriate equation for the neuron type
  126:         self.equations = equations_list[neuron_type]
  127  

  129          """
  130:         Creates a NeuronGroup of specified size using the model parameters.
  131  

  140              N=int(size * size),  # Total number of neurons (size x size)
  141:             model=self.equations,  # Neuron equations
  142              threshold="v > V_threshold",  # Spiking threshold condition
  143              reset="v = V_reset",  # Reset condition after spike
  144:             refractory=self.params["t_refract"],  # Refractory period
  145              method="linear",  # Numerical integration method

  148          # Assign parameter values to the NeuronGroup
  149:         neurons.Cm = self.params["Cm"]
  150:         neurons.g_leak = self.params["g_leak"]
  151:         neurons.V_rest = self.params["V_rest"]
  152:         neurons.sigma = self.params["sigma"]
  153:         neurons.ge = 0 * siemens  # Initial excitatory synaptic conductance
  154:         neurons.gi = 0 * siemens  # Initial inhibitory synaptic conductance
  155  

  157          neuron_indices = [(i, j) for i in range(size) for j in range(size)]
  158:         neurons.x = [i for i, j in neuron_indices]  # x-coordinate
  159:         neurons.y = [j for i, j in neuron_indices]  # y-coordinate
  160  
  161          # Set synaptic time constants based on neuron type
  162:         if self.neuron_type == "excitatory" or self.neuron_type == "input":
  163:             neurons.tau_ee = self.params[
  164                  "tau_ee"
  165              ]  # Excitatory-excitatory time constant
  166:             neurons.tau_ie = self.params[
  167                  "tau_ie"
  168              ]  # Inhibitory-excitatory time constant
  169:         elif self.neuron_type == "inhibitory":
  170:             neurons.tau_ei = self.params[
  171                  "tau_ei"
  172              ]  # Excitatory-inhibitory time constant
  173:             neurons.tau_ii = self.params[
  174                  "tau_ii"

spikes/archived/practice.ipynb:
   11       "text": [
   12:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l2_b1.5_t0.00_p0.00_g0.5.png\n",
   13:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l2_b1.5_t0.00_p3.14_g0.5.png\n",
   14:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l2_b1.5_t0.79_p0.00_g0.5.png\n",
   15:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l2_b1.5_t0.79_p3.14_g0.5.png\n",
   16:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l2_b1.5_t1.57_p0.00_g0.5.png\n",
   17:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l2_b1.5_t1.57_p3.14_g0.5.png\n",
   18:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l2_b1.5_t2.36_p0.00_g0.5.png\n",
   19:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l2_b1.5_t2.36_p3.14_g0.5.png\n",
   20:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l4_b1.5_t0.00_p0.00_g0.5.png\n",
   21:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l4_b1.5_t0.00_p3.14_g0.5.png\n",
   22:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l4_b1.5_t0.79_p0.00_g0.5.png\n",
   23:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l4_b1.5_t0.79_p3.14_g0.5.png\n",
   24:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l4_b1.5_t1.57_p0.00_g0.5.png\n",
   25:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l4_b1.5_t1.57_p3.14_g0.5.png\n",
   26:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l4_b1.5_t2.36_p0.00_g0.5.png\n",
   27:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l4_b1.5_t2.36_p3.14_g0.5.png\n",
   28:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l8_b1.5_t0.00_p0.00_g0.5.png\n",
   29:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l8_b1.5_t0.00_p3.14_g0.5.png\n",
   30:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l8_b1.5_t0.79_p0.00_g0.5.png\n",
   31:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l8_b1.5_t0.79_p3.14_g0.5.png\n",
   32:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l8_b1.5_t1.57_p0.00_g0.5.png\n",
   33:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l8_b1.5_t1.57_p3.14_g0.5.png\n",
   34:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l8_b1.5_t2.36_p0.00_g0.5.png\n",
   35:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l8_b1.5_t2.36_p3.14_g0.5.png\n",
   36:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l16_b1.5_t0.00_p0.00_g0.5.png\n",
   37:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l16_b1.5_t0.00_p3.14_g0.5.png\n",
   38:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l16_b1.5_t0.79_p0.00_g0.5.png\n",
   39:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l16_b1.5_t0.79_p3.14_g0.5.png\n",
   40:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l16_b1.5_t1.57_p0.00_g0.5.png\n",
   41:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l16_b1.5_t1.57_p3.14_g0.5.png\n",
   42:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l16_b1.5_t2.36_p0.00_g0.5.png\n",
   43:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l16_b1.5_t2.36_p3.14_g0.5.png\n",
   44:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l2_b1.5_t0.00_p0.00_g0.5.npy\n",
   45:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l2_b1.5_t0.00_p3.14_g0.5.npy\n",
   46:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l2_b1.5_t0.79_p0.00_g0.5.npy\n",
   47:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l2_b1.5_t0.79_p3.14_g0.5.npy\n",
   48:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l2_b1.5_t1.57_p0.00_g0.5.npy\n",
   49:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l2_b1.5_t1.57_p3.14_g0.5.npy\n",
   50:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l2_b1.5_t2.36_p0.00_g0.5.npy\n",
   51:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l2_b1.5_t2.36_p3.14_g0.5.npy\n",
   52:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l4_b1.5_t0.00_p0.00_g0.5.npy\n",
   53:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l4_b1.5_t0.00_p3.14_g0.5.npy\n",
   54:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l4_b1.5_t0.79_p0.00_g0.5.npy\n",
   55:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l4_b1.5_t0.79_p3.14_g0.5.npy\n",
   56:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l4_b1.5_t1.57_p0.00_g0.5.npy\n",
   57:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l4_b1.5_t1.57_p3.14_g0.5.npy\n",
   58:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l4_b1.5_t2.36_p0.00_g0.5.npy\n",
   59:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l4_b1.5_t2.36_p3.14_g0.5.npy\n",
   60:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l8_b1.5_t0.00_p0.00_g0.5.npy\n",
   61:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l8_b1.5_t0.00_p3.14_g0.5.npy\n",
   62:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l8_b1.5_t0.79_p0.00_g0.5.npy\n",
   63:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l8_b1.5_t0.79_p3.14_g0.5.npy\n",
   64:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l8_b1.5_t1.57_p0.00_g0.5.npy\n",
   65:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l8_b1.5_t1.57_p3.14_g0.5.npy\n",
   66:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l8_b1.5_t2.36_p0.00_g0.5.npy\n",
   67:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l8_b1.5_t2.36_p3.14_g0.5.npy\n",
   68:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l16_b1.5_t0.00_p0.00_g0.5.npy\n",
   69:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l16_b1.5_t0.00_p3.14_g0.5.npy\n",
   70:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l16_b1.5_t0.79_p0.00_g0.5.npy\n",
   71:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l16_b1.5_t0.79_p3.14_g0.5.npy\n",
   72:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l16_b1.5_t1.57_p0.00_g0.5.npy\n",
   73:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l16_b1.5_t1.57_p3.14_g0.5.npy\n",
   74:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l16_b1.5_t2.36_p0.00_g0.5.npy\n",
   75:       "Saved data/gabor_filters/eguchi_thesis/gabor128_l16_b1.5_t2.36_p3.14_g0.5.npy\n"
   76       ]

   87      "    '''\n",
   88:     "    This function makes a gabor_filter according to the values specified above.\n",
   89      "\n",
   90:     "    x and y are both \"meshgrids\". Basically you take two 1d arrays here representing locations on a 1d axis, and then use the np.meshgrid function to create two 2D arrays. \n",
   91:     "    The 2 2D arrays represent every possible combination of the two arrays, thereby creating the set of 2D coordinates. This means that you can perform matrix calculations on the two arrays.\n",
   92      "    '''\n",
   93      "    # Here x_prime and y_prime are calculated at each point\n",
   94:     "    x_prime = x * np.cos(theta) + y * np.sin(theta)\n",
   95:     "    y_prime = -x * np.sin(theta) + y * np.cos(theta)\n",
   96      "    \n",
   97      "    # Here sigma is calculated\n",
   98:     "    sigma = (lambda_ * (2**beta + 1)) / (np.pi * (2**beta - 1))\n",
   99      "\n",
  100      "    # Here the exponential and cosine component are calculated\n",
  101:     "    exp_component = np.exp(-(x_prime**2 + gamma**2 * y_prime**2) / (2 * sigma**2))\n",
  102:     "    cos_component = np.cos(2 * np.pi * x_prime / lambda_ + psi)\n",
  103      "    \n",

  107      "\n",
  108:     "def trim_filter(filter_array, threshold=0.05):\n",
  109:     "    mask = np.abs(filter_array) > threshold * np.max(np.abs(filter_array))\n",
  110:     "    if mask.any():\n",
  111:     "        coords = np.argwhere(mask)\n",
  112:     "        x_min, y_min = coords.min(axis=0)\n",
  113:     "        x_max, y_max = coords.max(axis=0) + 1\n",
  114      "        return filter_array[x_min:x_max, y_min:y_max]\n",

  119      "    trimmed_filter = trim_filter(filter_array)\n",
  120:     "    filename = f\"gabor{size}_l{lambda_}_b{beta}_t{theta:.2f}_p{psi:.2f}_g{gamma}.png\"\n",
  121:     "    filepath = os.path.join(directory, filename)\n",
  122:     "    normalized_filter = 255 * (trimmed_filter - np.min(trimmed_filter)) / (np.max(trimmed_filter) - np.min(trimmed_filter))\n",
  123:     "    image = Image.fromarray(normalized_filter.astype(np.uint8))\n",
  124:     "    image.save(filepath)\n",
  125      "    print(f\"Saved {filepath}\")\n",

  129      "    trimmed_filter = trim_filter(filter_array)\n",
  130:     "    filename = f\"gabor{size}_l{lambda_}_b{beta}_t{theta:.2f}_p{psi:.2f}_g{gamma}.npy\"\n",
  131:     "    filepath = os.path.join(directory, filename)\n",
  132:     "    np.save(filepath, trimmed_filter)\n",
  133      "    print(f\"Saved {filepath}\")\n",

  136      "def generate_and_save_filters(size, lambdas, betas, thetas, psis, gammas, directory, save_as_image=True):\n",
  137:     "    x = np.linspace(-size // 2, size // 2 - 1, size)\n",
  138:     "    y = np.linspace(-size // 2, size // 2 - 1, size)\n",
  139:     "    x, y = np.meshgrid(x, y)\n",
  140      "    for lambda_ in lambdas:\n",

  152      "directory_path = 'data/gabor_filters/eguchi_thesis'\n",
  153:     "os.makedirs(directory_path, exist_ok=True)\n",
  154      "lambdas = [2, 4, 8, 16]  # Wavelengths\n",
  155:     "betas = [1.5]  # Scaling factor for bandwidth\n",
  156:     "thetas = [0, np.pi/4, np.pi/2, 3*np.pi/4]  # Orientations\n",
  157:     "psis = [0, np.pi]  # Phase offsets\n",
  158:     "gammas = [0.5]  # Aspect ratio\n",
  159      "generate_and_save_filters(128, lambdas, betas, thetas, psis, gammas, directory_path, save_as_image=True)\n",

  174      "    def __init__(self, size, lambda_, beta, theta, psi, gamma):\n",
  175:     "        self.size = size\n",
  176:     "        self.lambda_ = lambda_\n",
  177:     "        self.beta = beta\n",
  178:     "        self.theta = theta\n",
  179:     "        self.psi = psi\n",
  180:     "        self.gamma = gamma\n",
  181:     "        self.x, self.y = self._generate_meshgrid(size)\n",
  182:     "        self.filter = self.generate_filter()\n",
  183      "\n",

  185      "        \"\"\"\n",
  186:     "        Generate meshgrid for Gabor filter based on the size.\n",
  187      "        \"\"\"\n",
  188:     "        x = np.linspace(-size // 2, size // 2 - 1, size)\n",
  189:     "        y = np.linspace(-size // 2, size // 2 - 1, size)\n",
  190:     "        return np.meshgrid(x, y)\n",
  191      "\n",

  193      "        \"\"\"\n",
  194:     "        Generate a Gabor filter based on the object's parameters.\n",
  195      "        \"\"\"\n",
  196:     "        x_prime = self.x * np.cos(self.theta) + self.y * np.sin(self.theta)\n",
  197:     "        y_prime = -self.x * np.sin(self.theta) + self.y * np.cos(self.theta)\n",
  198      "        \n",
  199:     "        sigma = (self.lambda_ * (2**self.beta + 1)) / (np.pi * (2**self.beta - 1))\n",
  200:     "        exp_component = np.exp(-(x_prime**2 + self.gamma**2 * y_prime**2) / (2 * sigma**2))\n",
  201:     "        cos_component = np.cos(2 * np.pi * x_prime / self.lambda_ + self.psi)\n",
  202      "        \n",

  204      "\n",
  205:     "    def trim_filter(self, filter_array, threshold=0.05):\n",
  206      "        \"\"\"\n",
  207:     "        Trim the Gabor filter to remove insignificant values based on a threshold.\n",
  208      "        \"\"\"\n",
  209:     "        mask = np.abs(filter_array) > threshold * np.max(np.abs(filter_array))\n",
  210:     "        if mask.any():\n",
  211:     "            coords = np.argwhere(mask)\n",
  212:     "            x_min, y_min = coords.min(axis=0)\n",
  213:     "            x_max, y_max = coords.max(axis=0) + 1\n",
  214      "            return filter_array[x_min:x_max, y_min:y_max]\n",

  221      "    def __init__(self, directory):\n",
  222:     "        self.directory = directory\n",
  223:     "        os.makedirs(directory, exist_ok=True)\n",
  224      "\n",

  226      "        \"\"\"\n",
  227:     "        Save the Gabor filter as a PNG image.\n",
  228      "        \"\"\"\n",
  229:     "        trimmed_filter = GaborFilter(size, lambda_, beta, theta, psi, gamma).trim_filter(filter_array)\n",
  230:     "        filename = f\"gabor{size}_l{lambda_}_b{beta}_t{theta:.2f}_p{psi:.2f}_g{gamma}.png\"\n",
  231:     "        filepath = os.path.join(self.directory, filename)\n",
  232      "\n",
  233:     "        normalized_filter = 255 * (trimmed_filter - np.min(trimmed_filter)) / (np.max(trimmed_filter) - np.min(trimmed_filter))\n",
  234:     "        image = Image.fromarray(normalized_filter.astype(np.uint8))\n",
  235:     "        image.save(filepath)\n",
  236      "        print(f\"Saved image to {filepath}\")\n",

  239      "        \"\"\"\n",
  240:     "        Save the Gabor filter as a NumPy binary file.\n",
  241      "        \"\"\"\n",
  242:     "        trimmed_filter = GaborFilter(size, lambda_, beta, theta, psi, gamma).trim_filter(filter_array)\n",
  243:     "        filename = f\"gabor{size}_l{lambda_}_b{beta}_t{theta:.2f}_p{psi:.2f}_g{gamma}.npy\"\n",
  244:     "        filepath = os.path.join(self.directory, filename)\n",
  245:     "        np.save(filepath, trimmed_filter)\n",
  246      "        print(f\"Saved NumPy array to {filepath}\")\n",

  252      "lambdas = [2, 4, 8, 16]  # Wavelengths\n",
  253:     "betas = [1.5]  # Scaling factor for bandwidth\n",
  254:     "thetas = [0, np.pi/4, np.pi/2, 3*np.pi/4]  # Orientations\n",
  255:     "psis = [0, np.pi]  # Phase offsets\n",
  256:     "gammas = [0.5]  # Aspect ratio\n",
  257      "\n",

  310      "from PIL import Image\n",
  311:     "from scipy.ndimage import convolve\n",
  312:     "from scipy.signal import fftconvolve\n",
  313:     "import matplotlib.pyplot as plt\n",
  314      "\n",

  316      "def load_image(image_path):\n",
  317:     "    image = Image.open(image_path).convert('L')  # Convert to grayscale\n",
  318:     "    return np.array(image) / 255.0  # Normalize the image to 0-1 scale\n",
  319      "\n",

  322      "    filters = []\n",
  323:     "    filenames = [f for f in os.listdir(directory) if f.endswith('.npy')]\n",
  324      "    for filename in filenames:\n",
  325:     "        filter_path = os.path.join(directory, filename)\n",
  326:     "        gabor_filter = np.load(filter_path)\n",
  327:     "        filters.append(gabor_filter)\n",
  328      "    return filters\n",

  334      "        filtered_image = fftconvolve(image, gabor_filter, mode='same')\n",
  335:     "        filtered_images.append(filtered_image)\n",
  336      "        print(\"done\")\n",

  339      "# Load the test image\n",
  340:     "test_image_path = 'test.png'\n",
  341      "test_image = load_image(test_image_path)\n",

  369      "if filtered_images:\n",
  370:     "    plt.figure(figsize=(6, 6))  # Adjust size as needed\n",
  371:     "    plt.imshow(filtered_images[30], cmap='gray', vmin=-0.5,vmax=0.5)\n",
  372:     "    plt.colorbar()  # Optional, shows the intensity scale\n",
  373:     "    plt.title('First Filtered Image')\n",
  374:     "    plt.axis('off')  # Hide axes for better visualization\n",
  375:     "    plt.show()\n",
  376      "else:\n",
  377:     "    print(\"No filtered images to display.\")"
  378     ]

  382    "kernelspec": {
  383:    "display_name": ".venv",
  384     "language": "python",

  391     },
  392:    "file_extension": ".py",
  393     "mimetype": "text/x-python",

  396     "pygments_lexer": "ipython3",
  397:    "version": "3.12.0"
  398    }

spikes/archived/project_1.py:
    2  import numpy as n
    3: import matplotlib.pyplot as plt
    4: import matplotlib.animation as animation
    5  

   12      def __init__(self, Cm, g_leak, tau_m, V_rest, V_threshold, V_reset, V_reversal, t_refract, model_type='default'):
   13:         self.Cm = Cm
   14:         self.g_leak = g_leak
   15:         self.tau_m = tau_m
   16:         self.V_rest = V_rest
   17:         self.V_threshold = V_threshold
   18:         self.V_reset = V_reset
   19:         self.V_reversal = V_reversal
   20:         self.t_refract = t_refract
   21:         self.model_type = model_type
   22  

   25  
   26:     Basically, it will define synapses coming from either excitatory or inhibitory neurons.
   27      e refers to those which synapse onto excitatory cells;
   28:     i refers to those which synapse onto inhibitory cells.
   29:     Therefore, for excitatory neurons -> inhibitory neurons we should use the exc_syn_model.i
   30      """
   31      def __init__(self, exc_lambda, exc_tau, inh_lambda, inh_tau, alpha_C = None, alpha_D=None,tau_pre=None,tau_post=None,A_plus=None,A_minus=None):
   32:         self.e = {'lambda': exc_lambda, 'tau': exc_tau}
   33:         self.i = {'lambda': inh_lambda, 'tau': inh_tau}
   34  

   40      def __init__(self, exc_neuron_model, exc_syn_model, inh_neuron_model, inh_syn_model, sigma, I_ext=1 * nA):
   41:         self.cell_types = {
   42              'e': exc_neuron_model,

   45          
   46:         self.synaptic_params = {
   47              'e': exc_syn_model,

   51  
   52:         self.stdp_params = {
   53:             'alpha_C': 0.5,
   54:             'alpha_D': 0.5,
   55              'tau_pre': 3 * ms,
   56              'tau_post': 5 * ms,
   57:             'A_plus': 0.1,
   58:             'A_minus': 0.1
   59          }
   60:         self.I_ext = I_ext
   61:         self.sigma = sigma
   62  

   64          equation = '''
   65:         dv/dt = (V_rest-v)/tau_m + (ge * (V_reversal_e-v) + gi * (V_reversal_i-v)) / (tau_m*g_leak) + sigma*xi*(tau_m)**-0.5 : volt
   66          dge/dt = -ge/tau_e : siemens

   69          if stimulus: # place holder for now - return to later
   70:             equation.replace('+ sigma','+ I_ext/(tau_m*g_leak))+ sigma')  # Include the stimulus term if specified
   71  

   77      def __init__(self, Ne, Ni, num_layers, connection, neural_model):
   78:         super().__init__()
   79:         self.num_layers = num_layers
   80:         self.neural_model = neural_model
   81:         self.connection = connection
   82:         self.Ne = Ne
   83:         self.Ni = Ni
   84:         self.construct_network()
   85  
   86      def construct_network(self):
   87:         self.neuron_groups = []
   88:         self.synapses = []
   89:         self.monitors = []
   90:         self.positions = initialize_positions(N=self.Ne)
   91          ''' This is a function that constructs the VisNetNetwork

   95          exc_neuron_params = {
   96:             'V_rest': self.neural_model.cell_types['e'].V_rest,
   97:             'V_threshold': self.neural_model.cell_types['e'].V_threshold,
   98:             'V_reset': self.neural_model.cell_types['e'].V_reset,
   99:             'tau_m': self.neural_model.cell_types['e'].tau_m,
  100:             'V_reversal_e': self.neural_model.cell_types['e'].V_reversal,
  101:             'V_reversal_i': self.neural_model.cell_types['i'].V_reversal,
  102:             'g_leak': self.neural_model.cell_types['e'].g_leak,
  103:             'tau_e': self.neural_model.synaptic_params['e'].e['tau'],
  104:             'tau_i': self.neural_model.synaptic_params['i'].e['tau'],
  105:             'lambda_e': self.neural_model.synaptic_params['e'].e['lambda'],
  106:             'lambda_i': self.neural_model.synaptic_params['e'].i['lambda'],
  107:             'sigma': self.neural_model.sigma,
  108          }

  110          inh_neuron_params = {
  111:             'V_rest': self.neural_model.cell_types['i'].V_rest,
  112:             'V_threshold': self.neural_model.cell_types['i'].V_threshold,
  113:             'V_reset': self.neural_model.cell_types['i'].V_reset,
  114:             'tau_m': self.neural_model.cell_types['i'].tau_m,
  115:             'V_reversal_e': self.neural_model.cell_types['e'].V_reversal,
  116:             'V_reversal_i': self.neural_model.cell_types['i'].V_reversal,
  117:             'g_leak': self.neural_model.cell_types['i'].g_leak,
  118:             'tau_e': self.neural_model.synaptic_params['e'].i['tau'],
  119:             'tau_i': self.neural_model.synaptic_params['i'].i['tau'],
  120:             'lambda_e': self.neural_model.synaptic_params['i'].e['lambda'],
  121:             'lambda_i': self.neural_model.synaptic_params['i'].i['lambda'],
  122:             'sigma': self.neural_model.sigma,
  123          }

  125          S_ie = None
  126:         # Now we define the input layer, following the same logic as for the dummy variables. using a poisson group
  127:         # G_e = NeuronGroup(self.Ne,
  128:         #                   self.neural_model.generate_neuron_equation('e',stimulus=True),
  129          #                   threshold='v>V_threshold',

  132          G_e = PoissonGroup(Ne, rates='10 * Hz')  # Adjust rate as needed
  133:         self.add(self.poisson_input)
  134  

  137  
  138:         self.add(G_e)
  139:         self.neuron_groups.append((G_e, G_i))
  140          '''
  141          Because we have to synapse onto the next layer, the synapses for layer 0 are actually 
  142:         generated alongside neurons for layer 1. Incidentally, because we use 0 index, the range works as intended
  143:         The first time round, it generates E & I cells for layer 1 and adds them to neuron_group[1].
  144          Then when we access neuron_groups[layer] we get (G_e<input>, None)

  147          '''
  148:         for layer in range(self.num_layers):
  149              print(f"completing neurons of layer {layer+1}")
  150:             G_e = NeuronGroup(self.Ne,
  151:                               self.neural_model.generate_neuron_equation('e'),
  152                                threshold=f'v > V_threshold',

  155  
  156:             G_i = NeuronGroup(self.Ni,
  157:                               self.neural_model.generate_neuron_equation('i'),
  158                                threshold=f'v > V_threshold',

  160                                namespace=inh_neuron_params)
  161:             self.add(G_e, G_i)
  162:             self.neuron_groups.append((G_e, G_i))
  163:             G_e_prev, G_i_prev = self.neuron_groups[layer]
  164              print(f"building synapses of layer {layer}")

  175                  print(f"connecting synapses of layer {layer}")
  176:                 S_ff.connect(j='i')
  177              else:

  194                      ''',
  195:                     namespace={**exc_neuron_params,**neural_model.stdp_params}
  196                  )
  197                  print(f"connecting synapses of layer {layer}")
  198:                 if self.connection == 'fc':
  199:                     S_ff.connect()
  200  
  201:                 elif self.connection == 'rf':
  202:                     S_ff.connect(condition='')
  203  
  204                  else:
  205:                     S_ff.connect(condition=self.connection)
  206:             self.add(S_ff)     
  207              '''
  208:             finally w append the synapses related to this the previous layer.
  209:             This includes all afferent connections.
  210              So having just made layer 1 neurons we have layer 0 synapses on the books
  211              '''
  212:             self.synapses.append((S_ff, S_ei, S_ie))
  213              # Now we can generate EI and IE connections for the current neuronal layer before the next loop (not plastic)

  228          print(f"connecting synapses of final layer")
  229:         S_ei.connect()
  230:         S_ie.connect()
  231  
  232:         self.add(S_ei)
  233:         self.add(S_ie)
  234          # at the end of the loop we just have to add layer N's neurons, we do this here
  235:         self.synapses.append((None, S_ei, S_ie))
  236          # Now we have all them connected, and completed according
  237      def add_monitors(self, layers, monitor_type='voltage', record_exc=True, record_inh=True, dt=None):
  238:         """Add monitors to specified layers and store them in a dictionary.
  239          
  240          Args:
  241:             layers (list): List of layer indices to add monitors.
  242:             monitor_type (str): 'voltage' or 'spike' to specify type of monitor.
  243:             record_exc (bool): If True, monitor excitatory neurons.
  244:             record_inh (bool): If True, monitor inhibitory neurons.
  245:             dt (Quantity): The time step for the monitor recording.
  246          
  247          Returns:
  248:             dict: A dictionary of monitors with keys as names.
  249              name = layer_0_exc_spike_monitor
  250          """
  251:         self.monitors = {}  # This could also be initialized in the __init__ if you want to access it elsewhere
  252          for layer_index in layers:
  253:             exc_neurons, inh_neurons = self.neuron_groups[layer_index]
  254              if record_exc and exc_neurons:

  259                      monitor = SpikeMonitor(exc_neurons)
  260:                 self.add(monitor)
  261:                 self.monitors[name] = monitor
  262  

  268                      monitor = SpikeMonitor(inh_neurons)
  269:                 self.add(monitor)
  270:                 self.monitors[name] = monitor
  271  
  272:         return self.monitors
  273      def initialize_positions(N, grid_type='square', width=None, height=None):
  274          if grid_type == 'square':
  275:             side = int(np.sqrt(N))  # Determine the side length of a square grid
  276              positions = [(x, y) for x in range(side) for y in range(side)]

  305      exc_tau = 2 * ms,
  306:     inh_lambda = 5.0 * nS,
  307      inh_tau = 2 * ms

  309  inh_syn_model = SynapticModel(
  310:     exc_lambda = 0.5 * nS,
  311      exc_tau = 5 * ms,
  312:     inh_lambda = 5.0 * nS,
  313      inh_tau = 5 * ms

  318  # Create an instance of NeuralModel
  319: neural_model = NeuralModel(e_neuron_model, exc_syn_model, i_neuron_model, inh_syn_model, 0.015 * mV)
  320  

  327  # Run the network
  328: voltage_monitor_input = StateMonitor(network.neuron_groups[0][0], 'v', record=True, dt=10*ms)
  329: voltage_monitor_first = StateMonitor(network.neuron_groups[1][0], 'v', record=True, dt=10*ms)
  330: voltage_monitor_second = StateMonitor(network.neuron_groups[2][0], 'v', record=True, dt=1*ms)
  331: network.add(voltage_monitor_input, voltage_monitor_first, voltage_monitor_second)
  332  

  334  print("Beginning run")
  335: network.run(20 * ms, report='text', report_period=2 * ms)
  336  print("Run completed")

  338  # Visualization setup
  339: fig, ax = plt.subplots()
  340  
  341  def update(frame):
  342:     ax.clear()
  343:     ax.set_title("Voltage Animation")
  344      
  345      for layer_index, voltage_monitor in enumerate(voltage_monitors):
  346:         voltages = voltage_monitor.v[:, frame]
  347          
  348          # Clip the voltages for color mapping
  349:         clipped_voltages = np.clip(voltages / mV, -80, 50)
  350:         colors = plt.cm.RdYlGn((clipped_voltages + 80) / 130)  # Scale between 0 and 1
  351          
  352          for i, voltage in enumerate(voltages):
  353:             ax.add_patch(plt.Rectangle((layer_index, i), 1, 1, color=colors[i]))
  354  
  355:     ax.set_xlim(0, len(voltage_monitors))
  356:     ax.set_ylim(0, max(Ne, Ni))
  357:     ax.set_xticks([])
  358:     ax.set_yticks([])
  359  
  360  # Create the color bar
  361: norm = plt.Normalize(vmin=-80, vmax=50)
  362: sm = plt.cm.ScalarMappable(cmap=plt.cm.RdYlGn, norm=norm)
  363: sm.set_array([])
  364  
  365: cbar = plt.colorbar(sm, ax=ax)
  366: cbar.set_label('Voltage (mV)')
  367  
  368: ani = animation.FuncAnimation(fig, update, frames=len(voltage_monitors[0].t), interval=20, repeat=False)
  369: plt.show()

spikes/archived/train_projects.py:
    7      """
    8:     from spikes.archived import project_1 as p1
    9  

   11      excit_neuron = '''
   12:     dv/dt = (V_rest_e-v)/tau_m_e + (ge*(V_reversal_e-v) + gi*(V_reversal_i-v))/(tau_m_e*g_leak_e) + sigma*xi*(tau_m_e)**-0.5 : volt
   13      dge/dt = -ge/tau_ee : siemens

   17      input_neuron = '''
   18:     dv/dt = (V_rest_e-v)/tau_m_e + (ge*(V_reversal_e-v) + gi*(V_reversal_i-v) + stimulus(t,i))/(tau_m_e*g_leak_e) + sigma*xi*(tau_m_e)**-0.5 : volt
   19      dge/dt = -ge/tau_ee : siemens

   23      inhib_neuron = '''
   24:     dv/dt = (V_rest_i-v)/tau_m_i + (ge*(V_reversal_e-v) + gi*(V_reversal_i-v))/(tau_m_i * g_leak_i) + sigma*xi*(tau_m_i)**-0.5 : volt
   25      dge/dt = -ge/tau_ei : siemens

   34  
   35:     excit_setup = {"N": p1.Ne,
   36              
   37:                      "model": p1.cell_E1,
   38:                      "threshold": 'v > p1.V_threshold_e',
   39:                      "reset": 'v=p1.V_reset_e',
   40:                      "refractory": p1.t_refract_e,
   41                       "method": 'euler'}
   42:     inhib_setup = {"N": p1.Ni,
   43:                    "model": p1.cell_I,
   44:                    "threshold": 'v > p1.V_threshold_i',
   45:                    "reset":'v=p1.V_reset_i',
   46:                    "refractory": p1.t_refract_i,
   47                     "method": 'euler'}

   58      # Setting up Synapses:
   59:     ei_setup = {"model": p1.syn_EI,
   60:                 "on_pre": p1.syn_EI_on_pre,
   61                  "delay": None,

   63      }
   64:     ie_setup = {"model": p1.syn_IE,
   65:                 "on_pre": p1.syn_IE_on_pre,
   66                  "delay": None,

   68      }
   69:     ee_setup = {"model": p1.syn_EE,
   70:                 "on_pre": p1.syn_EE_on_pre,
   71:                 "on_post": p1.syn_EE_on_post,
   72                  "delay": None,

   87      print("connecting excitatory")
   88:     l0_ee.connect(i= "j")
   89:     l1_ee.connect()
   90:     l2_ee.connect()
   91      print("connecting excitatory to inhib")
   92:     l1_ei.connect()
   93:     l2_ei.connect()
   94:     l3_ei.connect()
   95      print("connecting inhibitory to excitatory")
   96:     l1_ie.connect()
   97:     l2_ie.connect()
   98:     l3_ie.connect()
   99      '''

  117  
  118:     L1_EI.w = 1
  119:     L1_IE.w = 1
  120:     L1_EE.w = 'rand()'
  121:     L2_EI.w = 1
  122:     L2_IE.w = 1
  123:     L1_EE.plastic = True
  124  

spikes/input/__init__.py:
   1: # input/__init__.py
   2  
   3: # Import from gabor_filters.py
   4: from .gabor_filters import GaborFilter, GaborFilters
   5  
   6: # Import from convolution.py
   7: from .convolution import ConvLayer, ConvImage, convolve_dataset_with_gabor_filters
   8  
   9: # Import from mapping.py
  10: from .mapping import (
  11      NeuronInputs,

spikes/input/convolution.py:
    1: # convolution.py
    2  
    3  import numpy as np
    4: from scipy.signal import convolve2d
    5  from PIL import Image
    6: from concurrent.futures import ProcessPoolExecutor, as_completed
    7  from tqdm import tqdm

    9  
   10: from .gabor_filters import GaborFilter, GaborFilters  # Import from gabor_filters.py
   11  

   14      """
   15:     Class representing a single convolution layer.
   16      It stores the result of convolving an image with a Gabor filter,
   17:     and keeps track of the GaborFilter used for the convolution.
   18      """

   21          """
   22:         Initialize the ConvLayer with a GaborFilter object and the convolution result.
   23  
   24          Args:
   25:         gabor_filter (GaborFilter): The GaborFilter used for the convolution.
   26:         conv_result (ndarray): The result of convolving the image with the Gabor filter.
   27          """
   28:         self.gabor_filter = gabor_filter  # Store the GaborFilter used
   29:         self.conv_result = conv_result  # Store the convolution result
   30  

   32          """
   33:         Save the convolution result as a PNG image.
   34  
   35          Args:
   36:         directory (str): Directory where the image will be saved.
   37          """
   38:         filename = f"conv_l{self.gabor_filter.lambda_}_b{self.gabor_filter.beta}_t{self.gabor_filter.theta:.2f}_p{self.gabor_filter.psi:.2f}_g{self.gabor_filter.gamma}.png"
   39:         filepath = os.path.join(directory, filename)
   40  

   43              255
   44:             * (self.conv_result - np.min(self.conv_result))
   45:             / (np.max(self.conv_result) - np.min(self.conv_result))
   46          )
   47:         image = Image.fromarray(normalized_result.astype(np.uint8))
   48:         image.save(filepath)
   49          print(f"Saved convolution result to {filepath}")

   53      """
   54:     Class representing a collection of convolution layers.
   55      It stores multiple ConvLayer objects, each representing the result
   56:     of convolving an image with a different Gabor filter.
   57:     On initialization, all ConvLayer objects are created using the input image and GaborFilters.
   58      """

   61          """
   62:         Initialize the ConvImage by performing convolutions of the input image with each GaborFilter.
   63  
   64          Args:
   65:         gabor_filters (GaborFilters): The GaborFilters object containing multiple Gabor filters.
   66:         image (ndarray): The input image to be convolved with each Gabor filter.
   67          """
   68:         self.image = image  # Store the input image
   69:         self.gabor_filters = gabor_filters  # Store the GaborFilters object
   70:         self.layers = []  # List to store ConvLayer objects
   71  
   72:         self._create_conv_layers()  # Automatically create ConvLayer objects
   73  

   75          """
   76:         Create a ConvLayer for each Gabor filter by convolving the filter with the input image.
   77          """
   78          # Loop through all Gabor filters in the GaborFilters object
   79:         for gabor_filter in self.gabor_filters.filters:
   80              # Perform the 2D convolution between the image and the Gabor filter
   81              conv_result = convolve2d(
   82:                 self.image, gabor_filter.filter_array, mode="same", boundary="wrap"
   83              )

   88              # Add the ConvLayer to the list of layers
   89:             self.layers.append(conv_layer)
   90  

   92          """
   93:         Save all convolution results (layers) as images in the specified directory.
   94  
   95          Args:
   96:         directory (str): Directory where the images will be saved.
   97          """
   98:         for layer in self.layers:
   99:             layer.save_as_image(directory)
  100  

  102          """
  103:         Retrieve a ConvLayer by the parameters of the Gabor filter used.
  104  
  105          Args:
  106:         lambda_ (float): Wavelength of the desired Gabor filter.
  107:         beta (float): Scaling factor controlling bandwidth.
  108:         theta (float): Orientation of the desired filter in radians.
  109:         psi (float): Phase offset of the desired filter.
  110:         gamma (float): Aspect ratio of the desired filter.
  111  
  112          Returns:
  113:         ConvLayer: The ConvLayer object corresponding to the Gabor filter with the specified parameters.
  114  
  115          Raises:
  116:         ValueError: If no matching ConvLayer is found.
  117          """
  118          # Iterate through the list of ConvLayer objects
  119:         for layer in self.layers:
  120:             gabor_filter = layer.gabor_filter
  121              # Check if the Gabor filter parameters match the desired parameters
  122              if (
  123:                 gabor_filter.lambda_ == lambda_
  124:                 and gabor_filter.beta == beta
  125:                 and gabor_filter.theta == theta
  126:                 and gabor_filter.psi == psi
  127:                 and gabor_filter.gamma == gamma
  128              ):

  138  def convolve_image_with_gabor_filters(image, gabor_filters):
  139:     num_filters = len(gabor_filters.filters)
  140:     image_height, image_width = image.shape
  141:     convolved_image = np.zeros((image_height, image_width, num_filters))
  142  
  143      # Convolve the image with each Gabor filter
  144:     for filter_idx, gabor_filter in enumerate(gabor_filters.filters):
  145          convolved_image[:, :, filter_idx] = convolve2d(
  146:             image, gabor_filter.filter_array, mode="same", boundary="wrap"
  147          )

  154      """
  155:     Parallelize the convolution of each image in a dataset with a set of Gabor filters.
  156:     A progress bar is displayed using tqdm, and parallel execution is handled by ProcessPoolExecutor.
  157  
  158      Args:
  159:     dataset (ndarray): 3D array of images with shape (num_images, height, width).
  160:     gabor_filters (GaborFilters): GaborFilters object containing multiple filters.
  161  
  162      Returns:
  163:     4D ndarray: Convolved results with shape (num_images, height, width, num_filters).
  164      """
  165:     num_images, image_height, image_width = dataset.shape
  166      # Add a little debugger or
  167:     num_filters = len(gabor_filters.filters)
  168  
  169      # Initialize the 4D array to store convolved images
  170:     convolved_results = np.zeros((num_images, image_height, image_width, num_filters))
  171  

  175          futures = {
  176:             executor.submit(
  177                  convolve_image_with_gabor_filters, image, gabor_filters

  186              image_idx = futures[future]
  187:             convolved_results[image_idx] = future.result()
  188  

  193      """
  194:     Convolve each image in a dataset with a set of Gabor filters and return a 4D array.
  195      This is the crux of it - what we do with this convolved set is combined it with the mapping
  196      Args:
  197:     dataset (ndarray): 3D array of images with shape (num_images, height, width).
  198:     gabor_filters (GaborFilters): GaborFilters object containing multiple filters.
  199  
  200      Returns:
  201:     4D ndarray: Convolved results with shape (num_images, height, width, num_filters).
  202      """
  203:     num_images, image_height, image_width = dataset.shape
  204:     num_filters = len(gabor_filters.filters)
  205  
  206      # Initialize the 4D array to store convolved images
  207:     convolved_results = np.zeros((num_images, image_height, image_width, num_filters))
  208  

  211          # Loop over each Gabor filter
  212:         for filter_idx, gabor_filter in enumerate(gabor_filters.filters):
  213              # Convolve the image with the current Gabor filter
  214              convolved_image = convolve2d(
  215:                 image, gabor_filter.filter_array, mode="same", boundary="wrap"
  216              )

spikes/input/gabor_filters.py:
    1: # gabor_filters.py
    2  

   10      """
   11:     Class representing a single Gabor filter. Responsible for generating,
   12:     manipulating, and saving the Gabor filter based on the input parameters.
   13      """

   16          """
   17:         Initialize a GaborFilter object with specific parameters.
   18  
   19          Args:
   20:         size (int): Size of the square filter.
   21:         lambda_ (float): Wavelength of the sinusoidal factor.
   22:         beta (float): Scaling factor controlling bandwidth.
   23:         theta (float): Orientation of the Gabor filter in radians.
   24:         psi (float): Phase offset of the sinusoidal factor.
   25:         gamma (float): Aspect ratio of the Gaussian envelope.
   26          """
   27:         self.size = size  # Refactor this as not constant
   28:         self.lambda_ = lambda_
   29:         self.beta = beta
   30:         self.theta = theta
   31:         self.psi = psi
   32:         self.gamma = gamma
   33:         self.filter_array = self._generate_filter()
   34  

   36          """
   37:         Generate the meshgrid (x, y coordinates) for the Gabor filter based on size.
   38  
   39          Returns:
   40:         x, y (ndarray): Two 2D arrays representing the coordinates.
   41          """
   42:         x = np.linspace(-self.size // 2, self.size // 2 - 1, self.size)
   43:         y = np.linspace(-self.size // 2, self.size // 2 - 1, self.size)
   44:         return np.meshgrid(x, y)
   45  

   47          """
   48:         Generate the Gabor filter based on the object's parameters.
   49  
   50          Returns:
   51:         filter_array (ndarray): The 2D Gabor filter.
   52          """
   53:         x, y = self._generate_meshgrid()
   54          # Apply rotation to coordinates
   55:         x_prime = x * np.cos(self.theta) + y * np.sin(self.theta)
   56:         y_prime = -x * np.sin(self.theta) + y * np.cos(self.theta)
   57  
   58          # Compute sigma (standard deviation) for the Gaussian component
   59:         sigma = (self.lambda_ * (2**self.beta + 1)) / (np.pi * (2**self.beta - 1))
   60  
   61          # Calculate the exponential (Gaussian) and cosine (sinusoidal) components
   62:         exp_component = np.exp(
   63:             -(x_prime**2 + self.gamma**2 * y_prime**2) / (2 * sigma**2)
   64          )
   65:         cos_component = np.cos(2 * np.pi * x_prime / self.lambda_ + self.psi)
   66  

   70          """
   71:         Save the Gabor filter as a PNG image.
   72  
   73          Args:
   74:         directory (str): Directory where the image will be saved.
   75          """
   76:         filename = f"gabor_l{self.lambda_}_b{self.beta}_t{self.theta:.2f}_p{self.psi:.2f}_g{self.gamma}.png"
   77:         filepath = os.path.join(directory, filename)
   78  

   81              255
   82:             * (self.filter_array - np.min(self.filter_array))
   83:             / (np.max(self.filter_array) - np.min(self.filter_array))
   84          )
   85:         image = Image.fromarray(normalized_filter.astype(np.uint8))
   86:         image.save(filepath)
   87          print(f"Saved image to {filepath}")

   90          """
   91:         Save the Gabor filter as a NumPy array file (.npy).
   92  
   93          Args:
   94:         directory (str): Directory where the NumPy file will be saved.
   95          """
   96:         filename = f"gabor_l{self.lambda_}_b{self.beta}_t{self.theta:.2f}_p{self.psi:.2f}_g{self.gamma}.npy"
   97:         filepath = os.path.join(directory, filename)
   98:         np.save(filepath, self.filter_array)
   99          print(f"Saved NumPy array to {filepath}")

  104      Class responsible for generating, storing, and managing multiple Gabor filters
  105:     based on various combinations of parameters.
  106      """

  110          Initialize the GaborFilters object by generating and storing GaborFilter objects
  111:         for each combination of input parameters.
  112  
  113          Args:
  114:         size (int): Size of the square Gabor filters.
  115:         lambdas (list of floats): List of wavelengths for the filters.
  116:         betas (list of floats): List of scaling factors controlling bandwidth.
  117:         thetas (list of floats): List of orientations (angles) in radians.
  118:         psis (list of floats): List of phase offsets.
  119:         gammas (list of floats): List of aspect ratios.
  120          """
  121:         self.size = size
  122:         self.lambdas = lambdas
  123:         self.betas = betas
  124:         self.thetas = thetas
  125:         self.psis = psis
  126:         self.gammas = gammas
  127:         self.filters = []  # Store GaborFilter objects in a list
  128:         self._generate_all_filters()
  129  

  131          """
  132:         Generate all possible Gabor filters based on the provided parameter lists.
  133:         Each unique combination of parameters is used to create a GaborFilter object.
  134          """
  135:         # Use itertools.product to get every combination of the parameter values
  136          for lambda_, beta, theta, psi, gamma in product(
  137:             self.lambdas, self.betas, self.thetas, self.psis, self.gammas
  138          ):
  139              # Create a new GaborFilter instance for each parameter combination
  140:             gabor_filter = GaborFilter(self.size, lambda_, beta, theta, psi, gamma)
  141:             self.filters.append(gabor_filter)
  142  

  144          """
  145:         Retrieve a specific GaborFilter object based on its parameters.
  146  
  147          Args:
  148:         lambda_ (float): Wavelength of the desired filter.
  149:         beta (float): Scaling factor controlling bandwidth.
  150:         theta (float): Orientation of the desired filter in radians.
  151:         psi (float): Phase offset of the desired filter.
  152:         gamma (float): Aspect ratio of the desired filter.
  153  
  154          Returns:
  155:         GaborFilter: The Gabor filter object that matches the input parameters.
  156  
  157          Raises:
  158:         ValueError: If no filter is found with the specified parameters.
  159          """
  160          # Search the filters list for a GaborFilter object with matching parameters
  161:         for gabor_filter in self.filters:
  162              if (
  163:                 gabor_filter.lambda_ == lambda_
  164:                 and gabor_filter.beta == beta
  165:                 and gabor_filter.theta == theta
  166:                 and gabor_filter.psi == psi
  167:                 and gabor_filter.gamma == gamma
  168              ):

  171          raise ValueError(
  172:             f"Gabor filter with parameters lambda={lambda_}, beta={beta}, theta={theta}, psi={psi}, gamma={gamma} not found."
  173          )

  176          """
  177:         Save all stored Gabor filters as PNG images in the specified directory.
  178  
  179          Args:
  180:         directory (str): Directory where the images will be saved.
  181          """
  182:         for gabor_filter in self.filters:
  183:             gabor_filter.save_as_image(directory)
  184  

  186          """
  187:         Save all stored Gabor filters as NumPy array files (.npy) in the specified directory.
  188  
  189          Args:
  190:         directory (str): Directory where the NumPy files will be saved.
  191          """
  192:         for gabor_filter in self.filters:
  193:             gabor_filter.save_as_numpy(directory)

spikes/input/mapping.py:
    1: # mapping.py
    2  """
    3: Module Name: mapping.py
    4  ----------------------------------------------------

    7  --------
    8:     This module provides functionality for generating neuron input mappings from images using Gabor filters.
    9:     It includes classes and functions to create mappings, generate neuron inputs, and visualize the mappings.
   10:     The mappings are used to convert image data into neuron input data for further processing.
   11  

   15          Generates neuron inputs for a dataset by convolving images with
   16:     Gabor filters and mapping pixels to neurons.
   17  

   19          Generate a TimedArray from a 3D input array, where the input array
   20:     is assumed to be in the format (num_images, height, width).
   21  

   25          Class holding the 3D array of input along with the mapping that was
   26:     used to produce it.
   27      

   29          Class to generate and manage pixel mappings from image space to neuron
   30:     grid. Includes methods for generating mappings, generating neuron inputs, and visualizing mappings.
   31      

   33          Class to generate and manage pixel mappings from image space to neuron
   34:     grid using an older method. Includes methods for generating mappings and generating neuron inputs.
   35  

   49  """
   50: import matplotlib.pyplot as plt
   51: import matplotlib.animation as animation
   52  import numpy as np
   53  import random
   54: from concurrent.futures import ProcessPoolExecutor, as_completed
   55  from tqdm import tqdm

   57  
   58: from .convolution import convolve_dataset_with_gabor_filters
   59  
   60: from .gabor_filters import GaborFilters
   61  

   66      --------
   67:         Class to store neuron inputs along with the pixel mappings used to generate them.
   68  

   75          input_train (ndarray):
   76:             3D array of neuron inputs with shape (num_images, neuron_size, neuron_size).
   77          mapping (ImageMapping):
   78:             ImageMapping object containing the pixel mappings used to generate the neuron inputs.
   79      Methods:

   81          visualise:
   82:             Visualize the neuron inputs as a heatmap animation.
   83  

   92      def __init__(self, input_train, mapping):
   93:         self.input_train = input_train
   94:         self.mapping = mapping
   95  

   97          # Sample data for demonstration (replace 'neuron_inputs' with your actual data array)
   98:         fig, ax = plt.subplots()
   99  
  100          # Initialize a placeholder heatmap (use the first frame of data)
  101:         heatmap = ax.imshow(self.input_train[0], cmap="hot", interpolation="nearest")
  102:         ax.set_title("Layer 1")
  103  
  104          def update_heatmap(frame):
  105:             ax.clear()
  106              # Update the data in the heatmap (not creating a new one)
  107:             heatmap = ax.imshow(
  108:                 self.input_train[frame],
  109                  cmap="hot",

  111              )
  112:             ax.set_title(f"Layer {frame + 1}")
  113              return (heatmap,)
  114  
  115:         ani = animation.FuncAnimation(
  116:             fig, update_heatmap, frames=len(self.input_train), blit=True
  117          )

  119          # Adding a colorbar corresponding to the heatmap
  120:         plt.colorbar(heatmap, ax=ax)
  121  
  122:         plt.show()
  123  

  131      --------
  132:         Class to generate and manage pixel mappings from image space to neuron grid.
  133:         Includes methods for generating mappings, generating neuron inputs, and visualizing mappings.
  134      Details:

  140          image_size (int):
  141:             The size of the image (assumed square).
  142          neuron_size (int):
  143:             The size of the neuron array (assumed square).
  144          num_layers (int):
  145:             The number of layers in the convolved image stack (number of filters).
  146          num_total_pixels (int):
  147:             The total number of unique pixels to sample across layers (default: 100).
  148          radius (int):
  149:             The radius around the center of the pixel region for each neuron (default: 6).
  150          shape (str):
  151:             The shape of the eligible region, either "circle" or "square" (default: "circle").
  152          mapping (dict):
  153              A dictionary where each key is a (neuron_x, neuron_y) tuple and the value is
  154:         a list of randomly selected (x, y, layer) coordinates.
  155      Methods:

  157          generate_single_neuron_mapping:
  158:             generates a pixel mapping for a single neuron.
  159  
  160          gen_mappings:
  161:             generates pixel mappings for all neurons in parallel.
  162  
  163          gen_inputs:
  164:             generates neuron inputs from a 4D convolved dataset using precomputed 3D pixel mappings.
  165  
  166          visualize_neuron_mappings:
  167:             visualizes the pixel mappings for a set of randomly selected neurons.
  168      Example Usage:

  186          """
  187:         Initialize the ImageMapping object with the specified parameters & mapping or generate pixel mappings.
  188  

  190          ----------
  191:             image_size (int): The size of the image (assumed square).
  192:             neuron_size (int): The size of the neuron array (assumed square).
  193:             num_layers (int): The number of layers in the convolved image stack (number of filters).
  194:             num_total_pixels (int): The total number of unique pixels to sample across layers (default: 100).
  195:             radius (int): The radius around the center of the pixel region for each neuron (default: 6).
  196:             shape (str): The shape of the eligible region, either "circle" or "square" (default: "circle").
  197:             mapping (dict): A dictionary where each key is a (neuron_x, neuron_y) tuple and the value is a list of randomly selected (x, y, layer) coordinates.
  198  

  210          """
  211:         self.image_size = image_size
  212:         self.neuron_size = neuron_size
  213:         self.num_layers = num_layers
  214:         self.num_total_pixels = num_total_pixels
  215:         self.radius = radius
  216:         self.shape = shape
  217  
  218          if mapping:
  219:             self.mapping = mapping
  220          else:
  221:             self.mapping = self.gen_mappings(
  222                  image_size, neuron_size, num_layers, num_total_pixels, radius, shape

  237          """
  238:         Generate a pixel mapping for a single neuron (neuron_x, neuron_y) in the neuron grid.
  239  

  241          ----------
  242:         neuron_x (int): The x-coordinate of the neuron in the grid.
  243:         neuron_y (int): The y-coordinate of the neuron in the grid.
  244:         image_size (int): The size of the image (assumed square).
  245:         neuron_size (int): The size of the neuron array (assumed square).
  246:         num_layers (int): The number of layers in the convolved image stack (number of filters).
  247:         num_total_pixels (int): The total number of unique pixels to sample across layers.
  248:         radius (int): The radius around the center of the pixel region for each neuron.
  249:         shape (str): The shape of the eligible region, either "circle" or "square".
  250  

  252          --------
  253:         tuple: A tuple (neuron_x, neuron_y, selected_pixels) containing the neuron coordinates and the selected 3D pixels.
  254  

  277                  if shape == "circle":
  278:                     distance = np.sqrt((x - x_center) ** 2 + (y - y_center) ** 2)
  279                      if (

  281                      ):  # Only include pixels within the circular radius
  282:                         region_pixels.append((x, y))
  283                  elif shape == "square":
  284:                     region_pixels.append((x, y))
  285  

  293              print(
  294:                 f"Warning: Requested {num_total_pixels} pixels, but only {available_pixels} available for neuron ({neuron_x}, {neuron_y})."
  295              )

  305          # Randomly sample num_samples 3D coordinates
  306:         selected_pixels = random.sample(all_3d_coords, num_samples)
  307  

  315          """
  316:         Generate a pixel mapping for neurons in parallel, where each neuron is mapped to a subset of 3D pixels.
  317:         A progress bar is displayed to show the progress of mapping generation.
  318  

  320          dict: A dictionary where each key is a (neuron_x, neuron_y) tuple and the value is
  321:               a list of randomly selected (x, y, layer) coordinates.
  322          """

  329                  for neuron_y in range(neuron_size):
  330:                     futures.append(
  331:                         executor.submit(
  332:                             self.generate_single_neuron_mapping,
  333                              neuron_x,

  349              ):
  350:                 neuron_x, neuron_y, selected_pixels = future.result()
  351                  pixel_mappings[(neuron_x, neuron_y)] = selected_pixels

  356          """
  357:         Generate neuron inputs from a 4D convolved dataset using precomputed 3D pixel mappings.
  358  
  359          Args:
  360:         convolved_data (ndarray): 4D array of convolved images with shape (num_images, height, width, num_filters).
  361          pixel_mappings (obj): ImageMapping object - contains the correct
  362:         neuron_size (int): The size of the neuron array (e.g., 14 for a 14x14 neuron grid).
  363  
  364          Returns:
  365:         3D ndarray: Neuron inputs with shape (num_images, neuron_size, neuron_size) Here it's image_idx, neuron_y, neuron_x.
  366  
  367          Notes:
  368:         Basically it flips between matrix and cartesian coordinates, this is a bit confusing but hopefully it works out. The main thing is making sure that the right inputs are going to the right neurons
  369          """
  370:         num_images, image_height, image_width, num_filters = convolved_data.shape
  371:         neuron_size = self.neuron_size
  372          # Initialize the 3D array to store neuron inputs (num_images, neuron_size, neuron_size)
  373:         neuron_inputs = np.zeros((num_images, neuron_size, neuron_size))
  374  

  377              # Loop over each neuron
  378:             for neuron_x, neuron_y in self.mapping.keys():
  379                  # Get the precomputed 3D pixel mappings for this neuron
  380:                 selected_pixels = self.mapping[(neuron_x, neuron_y)]
  381  
  382                  # Collect pixel values from the convolved data based on the 3D coordinates
  383:                 input_values = np.array([])
  384  

  386                  for layer, x, y in selected_pixels:
  387:                     input_values = np.append(
  388                          # convolved_data is in the format (num_images, height, width, num_filters)

  394                  neuron_inputs[image_idx, neuron_y, neuron_x] = (
  395:                     np.sum(input_values[input_values > 0]) * 100
  396                  )  # Scale factor 100

  400          """
  401:         Visualize the pixel mappings for a set of randomly selected neurons.
  402          For each neuron, the selected pixels are shown, the center pixel is highlighted in blue,
  403:         and a blue boundary around the selection region is drawn.
  404  
  405          Args:
  406:         num_neurons (int): Number of random neurons to visualize (default: 10).
  407          """
  408:         import matplotlib.pyplot as plt
  409          import random
  410:         import matplotlib.patches as patches
  411  
  412:         if len(self.mapping) == 0:
  413:             print("No mappings available to visualize.")
  414              return

  416          # Randomly select neuron coordinates to visualize
  417:         random_neurons = random.sample(list(self.mapping.keys()), num_neurons)
  418  

  420          for neuron_x, neuron_y in random_neurons:
  421:             selected_pixels = self.mapping[(neuron_x, neuron_y)]
  422  
  423              # Initialize the base heatmap (empty image)
  424:             heatmap = np.zeros((self.image_size, self.image_size))
  425  

  430              # Visualize the heatmap
  431:             plt.figure(figsize=(6, 6))
  432:             plt.title(f"Neuron ({neuron_x}, {neuron_y}) - Pixel Mapping")
  433  
  434              # Show the heatmap in grey and red
  435:             plt.imshow(heatmap, cmap="Reds", interpolation="nearest")
  436  
  437              # Invert y-axis to correct for imshow's top-left origin behavior
  438:             plt.gca().invert_yaxis()
  439  
  440              # Highlight the neuron center pixel in blue
  441:             scale = self.image_size // self.neuron_size
  442              x_center = int(scale * neuron_x + scale / 2)
  443              y_center = int(scale * neuron_y + scale / 2)
  444:             plt.scatter(
  445                  x_center, y_center, color="blue", label="Neuron Center", s=100

  448              # Define the region bounds for the neuron selection
  449:             x_min = max(0, x_center - self.radius)
  450:             x_max = min(self.image_size - 1, x_center + self.radius)
  451:             y_min = max(0, y_center - self.radius)
  452:             y_max = min(self.image_size - 1, y_center + self.radius)
  453  
  454              # Draw a blue boundary around the region (correct x and y alignment)
  455:             rect = patches.Rectangle(
  456                  (x_min, y_min),

  458                  y_max - y_min,
  459:                 linewidth=1.5,
  460                  edgecolor="blue",

  463              )
  464:             plt.gca().add_patch(rect)
  465  
  466              # Add legend and show the plot
  467:             plt.legend(loc="upper right")
  468:             plt.xlabel("x-coordinate")
  469:             plt.ylabel("y-coordinate")
  470:             plt.show()
  471  

  483      ):
  484:         self.image_size = image_size
  485:         self.neuron_size = neuron_size
  486:         self.num_layers = num_layers
  487:         self.num_total_pixels = num_total_pixels
  488:         self.radius = radius
  489:         self.shape = shape
  490:         self.mapping = self.gen_mappings(
  491              image_size, neuron_size, num_layers, num_total_pixels, radius, shape

  498          Generate a pixel mapping for neurons where each neuron is mapped to a subset of 3D pixels
  499:         (x, y, layer) from an image, within a radius around its corresponding position. The region can be
  500:         either circular or square.
  501  
  502          Args:
  503:         image_size (int): The size of the image (assumed square).
  504:         neuron_size (int): The size of the neuron array (assumed square).
  505:         num_layers (int): The number of layers in the convolved image stack (number of filters).
  506:         num_total_pixels (int): The total number of unique pixels to sample across layers (default: 100).
  507:         radius (int): The radius around the neuron center in the image (default: 6).
  508:         shape (str): The shape of the eligible region, either "circle" or "square" (default: "circle").
  509  

  511          dict: A dictionary where each key is a (neuron_x, neuron_y) tuple and the value is
  512:                 a list of randomly selected (x, y, layer) coordinates.
  513          """

  537                              # Compute the Euclidean distance from the center
  538:                             distance = np.sqrt(
  539                                  (x - x_center) ** 2 + (y - y_center) ** 2

  542                              if distance <= radius:
  543:                                 region_pixels.append((x, y))
  544                          elif shape == "square":
  545                              # Include all pixels within the bounding box for a square
  546:                             region_pixels.append((x, y))
  547  

  555                      print(
  556:                         f"Warning: Requested {num_total_pixels} pixels, but only {available_pixels} available for neuron ({neuron_x}, {neuron_y})."
  557                      )

  572                  # Randomly sample num_samples 3D coordinates without replacement
  573:                 selected_pixels = random.sample(all_3d_coords, num_samples)
  574  

  581          """
  582:         Generate neuron inputs from a 4D convolved dataset using precomputed 3D pixel mappings.
  583  
  584          Args:
  585:         convolved_data (ndarray): 4D array of convolved images with shape (num_images, height, width, num_filters).
  586          pixel_mappings (obj): ImageMapping object - contains the correct
  587:         neuron_size (int): The size of the neuron array (e.g., 14 for a 14x14 neuron grid).
  588  
  589          Returns:
  590:         3D ndarray: Neuron inputs with shape (num_images, neuron_size, neuron_size).
  591          """
  592:         num_images, image_height, image_width, num_filters = convolved_data.shape
  593:         neuron_size = self.neuron_size
  594:         image_mapping = self.mapping
  595          # Initialize the 3D array to store neuron inputs (num_images, neuron_size, neuron_size)
  596:         neuron_inputs = np.zeros((num_images, neuron_size, neuron_size))
  597  

  600              # Loop over each neuron
  601:             for neuron_x, neuron_y in image_mapping.keys():
  602                  # Get the precomputed 3D pixel mappings for this neuron

  607                  for layer, x, y in selected_pixels:
  608:                     input_values.append(convolved_data[image_idx, x, y, layer])
  609  
  610                  # Average the input values to assign to the neuron
  611:                 neuron_inputs[image_idx, neuron_x, neuron_y] = np.mean(input_values)
  612  

  625      """
  626:     Generate neuron inputs for a dataset by convolving images with Gabor filters and mapping pixels to neurons.
  627  
  628      Args:
  629:     dataset (ndarray): 3D array of images with shape (num_images, height, width).
  630      Basically it's channel first
  631:     gabor_filters (GaborFilters): GaborFilters object containing multiple filters.
  632:     neuron_size (int): Size of the neuron grid (e.g., 14 for 14x14 neurons).
  633:     image_size (int): Size of the input images (e.g., 28x28).
  634:     num_total_pixels (int): Number of pixels to sample for each neuron.
  635:     radius (int): Radius around the center of the pixel region for each neuron.
  636:     shape (str): Shape of the region ("circle" or "square").
  637  
  638      Returns:
  639:     NeuronInputs: NeuronInputs object containing the 3D array of neuron inputs and the pixel mappings.
  640      """

  644      # Step 2: Generate pixel mappings from the image space to the neuron grid
  645:     num_layers = len(gabor_filters.filters)
  646      image_mapping = ImageMapping(

  650      # Step 3: Generate neuron inputs using the 3D pixel mappings
  651:     neuron_train = image_mapping.gen_inputs(convolved_data)
  652      neuron_inputs = NeuronInputs(neuron_train, image_mapping)

  660      Generate a TimedArray from a 3D input array, where the input array is assumed to be
  661:     in the format (num_images, height, width).
  662  
  663      Args:
  664:     input (ndarray): 3D input array with shape (num_images, height, width).
  665  
  666      Returns:
  667:     TimedArray: TimedArray object with the input values.
  668      """
  669:     neuron_input_train = neuron_inputs.input_train
  670:     index, height, width = neuron_input_train.shape
  671      print(

  675      # Gonna have to sort the dimensions here unfortunately - what a hassle
  676:     collapsed_input = np.array(
  677:         [neuron_input_train.flatten() for image in neuron_input_train]
  678      )

spikes/network/__init__.py:
   1: # network/__init__.py
   2  
   3: # Import from equations.py
   4: from .equations import EquationsContainer
   5  
   6: # Import from neurons.py
   7: from .neurons import NeuronSpecs
   8  
   9: # Import from synapses.py
  10: from .synapses import StdpSynapseSpecs, NonStdpSynapseSpecs  # InputSynapseSpecs
  11  
  12: # Import from create_network.py
  13: from .create_network import (
  14      create_neuron_groups,

spikes/network/create_network.py:
    1  """
    2: Module Name: create_network.py
    3  ----------------------------------------------------

    7      This module provides functions to create and wire neuron and synapse
    8: groups using Brian2 in a manner akin to a VisNet model.
    9  

   17          Generates n layers of excitatory and inhibitory neurons, 
   18:     wiring them up according to the neuron specifications provided.
   19  

   21          Takes a VisNet Neuron model and creates synapses between the layers of neurons
   22:     according to the synapse specifications provided.
   23  

   25          creates an input layer of poisson neurons and wires them to the first
   26:     excitatory layer of the network.
   27  

   53  from brian2 import *
   54: from .neurons import NeuronSpecs
   55: from .synapses import StdpSynapseSpecs, NonStdpSynapseSpecs
   56  

   67          Generates n layers of excitatory and inhibitory neurons,
   68:     wiring them up according to the neuron specifications provided.
   69  

   71      -------
   72:         It iterates over a range generated on n_layers, indexing layers from 1.
   73:     So for a range(3) it will create layers 1, 2, and 3.
   74:         This means we can define the poissongroup or input layer as layer 0.
   75:         For each layer it calls the create_neurons method of the NeuronSpecs class.
   76      Parameters:

   78          network (Network):
   79:             The Brian2 network object to add the neurons to.
   80          n_layers (int):
   81:             Number of layers in the network.
   82          exc_neuron_specs (NeuronSpecs)
   83:             Specifications for the excitatory neuron group.
   84          inh_neuron_specs (NeuronSpecs)
   85:             Specifications for the inhibitory neuron group.
   86  

  100          We want to add flexibility in specifying the number of neurons and synapses,
  101:     and whether we do back and lateral.
  102      """

  109          # Create excitatory and inhibitory neuron groups for each layer
  110:         exc_neuron_specs.create_neurons(layer, target_network=network)
  111:         inh_neuron_specs.create_neurons(layer, target_network=network)
  112  

  125      Takes a VisNet Neuron model and creates synapses between the layers of neurons
  126:     according to the synapse specifications provided.
  127  

  133      network (Network):
  134:         The Brian2 network object to add the synapses to.
  135      n_layers (int):
  136:         Number of layers in the network.
  137      exc_neuron_specs (NeuronSpecs):
  138:         Specifications for the excitatory neuron group.
  139      inh_neuron_specs (NeuronSpecs):
  140:         Specifications for the inhibitory neuron group.
  141      stdp_synapse_specs (StdpSynapseSpecs):
  142:         Specifications for the STDP synapse group.
  143      non_stdp_synapse_specs (NonStdpSynapseSpecs):
  144:         Specifications for the non-STDP synapse group.
  145  

  171              print(f"creating E-E synapses for layer {layer}")
  172:             stdp_synapse_specs.create_synapses(
  173                  layer,

  181          print(f"creating E-I synapses for layer {layer}")
  182:         non_stdp_synapse_specs.create_synapses(
  183              layer, exc_neuron_specs, inh_neuron_specs, radius=2, target_network=network

  187          print(f"creating I-E synapses for layer {layer}")
  188:         non_stdp_synapse_specs.create_synapses(
  189              layer, inh_neuron_specs, exc_neuron_specs, radius=2, target_network=network

  193          print(f"creating I-I synapses for layer {layer}")
  194:         non_stdp_synapse_specs.create_synapses(
  195              layer, inh_neuron_specs, inh_neuron_specs, radius=2, target_network=network

  205      Creates an input layer of Poisson neurons and wires them to the first
  206:     excitatory layer of the network.
  207  

  210      network : Network
  211:         The neural network to which the input layer and synapses will be added.
  212      exc_neuron_specs : NeuronSpecs
  213:         Specifications of the excitatory neurons, including neuron groups.
  214      timed_input : TimedArray
  215:         Defines the time-dependent input rates for the Poisson neurons.
  216  

  219          input_synapses (Synapses):
  220:         The synapses created between the Poisson input layer and the first excitatory layer.
  221  

  232      """
  233:     exc_neuron_layer_1 = exc_neuron_specs.neuron_groups["excitatory_layer_1"]
  234      timed_input = timed_input
  235      poisson_neurons = PoissonGroup(
  236:         exc_neuron_layer_1.N,
  237          rates="timed_input((t%epoch_length),i)",  # let's the timed_input indefinitely loop I hope

  239      )
  240:     network.add(poisson_neurons)
  241      input_synapses = Synapses(

  246      )
  247:     network.add(input_synapses)
  248:     input_synapses.connect(i="j")
  249      return input_synapses

  254  #     """
  255: #     Search for an object by its name in a given Network.
  256  
  257  #     Parameters:
  258: #     - network: The Network object to search in.
  259: #     - name: The name of the object to find (string).
  260  
  261  #     Returns:
  262: #     - The object if found, or None if not found.
  263  #     """
  264  
  265: #     for obj in network.objects:
  266  #         print(obj[0][0])
  267: #         # if hasattr(obj.NeuronGroup, "name"):
  268: #         if obj.name == name:
  269  #             return obj
  270: #     raise Warning(f"Object with name '{name}' not found in the network.")
  271  
  272  
  273: # def generate_inputs(input: np.array):
  274  #     """
  275: #     input vector is a 3D array. We're assuming it goes index, height, width
  276  #     """
  277  #     stimulus_exposure_time = 10 * ms
  278: #     index, height, width = input.shape
  279  #     print(

  283  #     # Gonna have to sort the dimensions here unfortunately - what a hassle
  284: #     collapsed_input = np.array([input.flatten() for image in input])
  285  #     collapsed_input_hz = collapsed_input * 100 * hertz

  304  #     """
  305: #     excitatory_layer_1 = exc_neuron_specs.neuron_groups["excitatory_layer_1"]
  306: #     print(excitatory_layer_1.ge)
  307: #     input_synapse_specs.create_synapses(poisson_neurons, excitatory_layer_1, network)

spikes/network/equations.py:
    1  """
    2: Module Name: equations.py
    3  ----------------------------------------------------

    7      This module provides functionality for storing and managing different sets of equations for neurons, synapses,
    8:     and other models in a neural network. It includes a class to store and retrieve these equations, as well as
    9:     methods to add basic and custom equations.
   10  

   17      EquationsContainer:
   18:         A container to store different sets of equations for neurons, synapses, and other models in the network.
   19:         Includes methods to initialize the container, add basic equations, and add custom equations.
   20  

   28      custom_equation = Equations("dv/dt = -v/tau : volt")
   29:     container.add_equation("neuron", "custom_neuron", custom_equation)
   30  

   32  --------------------
   33:     This module relies on the Brian2 library for defining and managing equations.
   34  """

   42      A container to store different sets of equations for neurons, synapses,
   43:     and other models in the network.
   44  

   47      neuron_equations : dict
   48:         Dictionary storing equations for different types of neurons (e.g., excitatory, inhibitory).
   49      synaptic_equations : dict
   50:         Dictionary storing equations for different types of synapses (future expansion).
   51      other_equations : dict
   52:         Dictionary storing other types of equations if needed.
   53  

   56      add_basic_equations:
   57:         Adds basic neuron equations for excitatory, inhibitory, and input neurons to the neuron_equations dictionary.
   58  

   62          """
   63:         Initialize empty dictionaries for neuron, synaptic, and other equations.
   64:         Adds basic equations for excitatory, inhibitory, and input neurons.
   65          """
   66          # Initialise the dictionaries for different equations
   67:         self.neuron_equations = {}
   68:         self.synaptic_equations = {}
   69:         self.other_equations = {}
   70  
   71          # Call function to add basic equations
   72:         self.add_basic_equations()
   73  

   76          Adds basic neuron equations for excitatory, inhibitory, and input neurons
   77:         to the neuron_equations dictionary.
   78          """

   82              """
   83:             dv/dt = (V_rest-v)/tau_m + (ge*(V_reversal_e-v) + gi*(V_reversal_i-v))/(tau_m*g_leak) + sigma*xi*(tau_m)**-0.5 : volt
   84              dge/dt = -ge/tau_ee : siemens

  105              """
  106:             dv/dt = (V_rest-v)/tau_m + (ge*(V_reversal_e-v) + gi*(V_reversal_i-v))/(tau_m * g_leak) + sigma*xi*(tau_m)**-0.5 : volt
  107              dge/dt = -ge/tau_ei : siemens

  128              """
  129:             dv/dt = (V_rest-v)/tau_m + (ge*(V_reversal_e-v) + gi*(V_reversal_i-v))/(tau_m*g_leak) + sigma*xi*(tau_m)**-0.5 : volt
  130              dge/dt = -ge/tau_ee : siemens

  179          # Define input neuron equations
  180:         self.neuron_equations["excitatory"] = excitatory_model
  181:         self.neuron_equations["inhibitory"] = inhibitory_model
  182:         self.neuron_equations["input"] = input_model
  183  

  185          """
  186:         Adds a custom equation to the appropriate dictionary based on the type.
  187  

  190          eq_type : str
  191:             The type of equation ('neuron', 'synaptic', or 'other').
  192          equation_name : str
  193:             Name of the equation to be stored.
  194          equation_body : Equations
  195:             The body of the equation as a Brian2 Equations object.
  196  

  198          -------
  199:         ValueError if an unknown equation type is provided.
  200          """

  203          if eq_type == "neuron":
  204:             self.neuron_equations[equation_name] = equation_body
  205          elif eq_type == "synaptic":
  206:             self.synaptic_equations[equation_name] = equation_body
  207          elif eq_type == "other":
  208:             self.other_equations[equation_name] = equation_body
  209          else:

spikes/network/neurons.py:
    2  
    3: # neurons.py
    4  """
    5: Module Name: neurons.py
    6  ----------------------------------------------------

    9  --------
   10:     This module provides classes and functions for defining and managing neuron parameters and specifications.
   11:     It includes functionality for validating neuron parameters, creating neuron groups, and adding variables to neuron groups.
   12  

   15      NeuronParameters:
   16:         Class to hold and validate neuron parameters such as membrane capacitance, leak conductance, firing threshold voltage, etc.
   17  
   18      NeuronSpecs:
   19:         Class to hold neuron specifications such as type, length, and corresponding parameters. It includes methods for creating neurons and adding variables to neuron groups.
   20  

   23      equations (EquationsContainer):
   24:         An instance of EquationsContainer used to store global equations for neurons.
   25  

   34  
   35: from .equations import EquationsContainer
   36  import warnings

   44      """
   45:     Class to hold and validate neuron parameters.
   46  

   48      -----------
   49:     cm : farad | Membrane capacitance.
   50      g_leak : siemens
   51:         Leak conductance.
   52      v_threshold : volt
   53:         Firing threshold voltage.
   54      v_reset : volt
   55:         Reset voltage after a spike.
   56      v_rest : volt
   57:         Resting potential.
   58      v_reversal_e : volt
   59:         Reversal potential for excitatory synapses.
   60      v_reversal_i : volt
   61:         Reversal potential for inhibitory synapses.
   62      sigma : volt
   63:         Noise term.
   64      tau_m : second
   65:         Membrane time constant.
   66      tau_ee : second
   67:         Time constant for excitatory-excitatory synapses.
   68      tau_ei : second
   69:         Time constant for excitatory-inhibitory synapses.
   70      tau_ie : second
   71:         Time constant for inhibitory-excitatory synapses.
   72      tau_ii : second
   73:         Time constant for inhibitory-inhibitory synapses.
   74      neuron_type : str
   75:         Type of neuron ('excitatory' or 'inhibitory').
   76      """

   95          # Validate the parameters provided by calling the check_valid_parameters function
   96:         self.check_valid_parameters(
   97              cm=cm,

  113          # Assign validated parameters to the class attributes
  114:         self.cm = cm
  115:         self.g_leak = g_leak
  116:         self.v_threshold = v_threshold
  117:         self.v_reset = v_reset
  118:         self.v_rest = v_rest
  119:         self.v_reversal_e = v_reversal_e
  120:         self.v_reversal_i = v_reversal_i
  121:         self.sigma = sigma
  122:         self.tau_m = tau_m
  123:         self.tau_ee = tau_ee
  124:         self.tau_ei = tau_ei
  125:         self.tau_ie = tau_ie
  126:         self.tau_ii = tau_ii
  127  
  128          # Assign a list to keep track of all groups made with these specs
  129:         self.neuron_groups = []
  130  

  132          """
  133:         Checks if all provided parameters are valid (non-None).
  134:         Also warns if the neuron_type is unspecified but tau values imply a specific type.
  135  

  138          params : dict
  139:             Dictionary of all neuron parameters to be validated.
  140  

  142          -------
  143:         ValueError if any required parameter is not specified.
  144          """
  145          # Explicitly remove "neuron_type" from the params dictionary before checking
  146:         neuron_type = params.pop("neuron_type", None)  # Remove and store neuron_type
  147  
  148:         # Ensure all parameters are provided (i.e., not None)
  149:         for name, param in params.items():
  150              if param is None:
  151:                 warnings.warn(f"Parameter {name} must be specified (non-None).")
  152  

  156                  raise Warning(
  157:                     f"Neuron type unspecified. It appears to be excitatory based on tau_ee ({params['tau_ee']}) and tau_ie ({params['tau_ie']}). "
  158:                     f"Consider specifying neuron_type as 'excitatory' for clarity."
  159                  )

  161                  raise Warning(
  162:                     f"Neuron type unspecified. It appears to be inhibitory based on tau_ei ({params['tau_ei']}) and tau_ii ({params['tau_ii']}). "
  163:                     f"Consider specifying neuron_type as 'inhibitory' for clarity."
  164                  )

  172              ):
  173:                 warnings.warn(
  174:                     f"Mismatch in conductance parameters for type 'excitatory'. Check the following:\n"
  175                      f"tau_ee: {params['tau_ee']} [expected positive value]\n"

  187              ):
  188:                 warnings.warn(
  189:                     f"Mismatch in conductance parameters for type 'inhibitory'. Check the following:\n"
  190                      f"tau_ee: {params['tau_ee']} [expected no value]\n"

  198      """
  199:     Class to hold neuron specifications such as type, length, and corresponding parameters.
  200  

  203      neuron_type : str
  204:         Type of the neuron ('excitatory', 'inhibitory', etc.).
  205      length : int
  206:         length of the neuron group (e.g., grid dimensions for spatially organized groups).
  207:     cm, g_leak, v_threshold, etc. : various types
  208:         Neuron parameters required to initialize the group.
  209      """

  230          # Store neuron type and length, and validate neuron parameters
  231:         self.neuron_type = neuron_type
  232:         self.length = length
  233:         self.parameters = NeuronParameters(
  234              cm,

  248          )
  249:         self.neuron_groups = {}
  250  

  252          """
  253:         Creates neurons in the given layer.
  254  

  257          layer : int
  258:             The current layer number where neurons should be created.
  259          target_network : optional
  260:             The target_network network to which the neurons should be added (optional).
  261  

  264          neurons : NeuronGroup
  265:             The instantiated neuron group with the parameters specified.
  266  

  268          --------
  269:         add these neurons to some list of neuron groups attached to this type as well, and on init add neuron groups to some buffer somewhere? IDK how that would work... look into it same as network baso
  270:         I guess on inport of module import that buffer so it hangs out in the background...
  271          maybe add some list which captures all neurongroups made according to this template, perhaps include it in some mapping feature as well - say if we could add all

  275          # Retrieve the appropriate equation model for the neuron type
  276:         model = equations.neuron_equations[self.neuron_type]
  277:         neuron_group_name = f"{self.neuron_type}_layer_{layer}"
  278          # Create the neuron group with a threshold and reset condition
  279          neurons = NeuronGroup(
  280:             N=int(self.length**2),
  281              model=model,

  286          # Add additional parameters to the neuron group
  287:         self.add_variables(neurons)
  288:         self.neuron_groups[neuron_group_name] = neurons
  289          if not target_network == None:
  290              print(f"adding layer{layer} neurons to network")
  291:             target_network.add(neurons)
  292          return neurons

  295          """
  296:         Adds parameters as variables to the neuron group.
  297  

  300          neurons : NeuronGroup
  301:             The neuron group to which variables will be added.
  302          """

  304          # Assign membrane, conductance, and voltage-related parameters
  305:         neurons.Cm = self.parameters.cm
  306:         neurons.g_leak = self.parameters.g_leak
  307:         neurons.V_rest = self.parameters.v_rest
  308:         neurons.V_reset = self.parameters.v_reset
  309:         neurons.V_reversal_e = self.parameters.v_reversal_e
  310:         neurons.V_reversal_i = self.parameters.v_reversal_i
  311:         neurons.V_threshold = self.parameters.v_threshold
  312:         neurons.sigma = self.parameters.sigma
  313:         neurons.tau_m = self.parameters.tau_m
  314  
  315          # Add synaptic time constants where applicable
  316:         if self.parameters.tau_ee:
  317:             neurons.tau_ee = self.parameters.tau_ee
  318:         if self.parameters.tau_ei:
  319:             neurons.tau_ei = self.parameters.tau_ei
  320:         if self.parameters.tau_ie:
  321:             neurons.tau_ie = self.parameters.tau_ie
  322:         if self.parameters.tau_ii:
  323:             neurons.tau_ii = self.parameters.tau_ii
  324  
  325          # Optionally assign x and y coordinates if spatial mapping is necessary
  326:         self.add_rows_and_columns(neurons, self.length)
  327  

  329          """
  330:         Assigns rows and columns to neurons in the grid (if necessary).
  331:         The actual implementation for spatial assignments is yet to be added.
  332  

  335          neurons : NeuronGroup
  336:             The neuron group for which indexes are to be set.
  337  

  359          """
  360:         columns = np.tile(np.arange(length), length)
  361:         rows = np.repeat(np.arange(length), length)
  362:         neurons.column = columns
  363:         neurons.row = rows

spikes/network/synapses.py:
    3  """
    4: Module Name: synapses.py
    5  ----------------------------------------------------

    8  --------
    9:     This module provides functionality for defining and managing synapse specifications and connections in a neural network.
   10:     It includes base classes and specific implementations for different types of synapses, such as STDP and non-STDP synapses.
   11:     The module also provides methods for creating synapses, connecting them, setting their parameters, and visualizing the connections.
   12  

   15      SynapseParameters:
   16:         Class for initializing and validating synapse parameters. It restricts the parameters to a predefined set of 
   17:     values and checks their validity based on the synapse type. 
   18  
   19      SynapseSpecsBase:
   20:         Abstract base class for defining synapse specifications and handling synapse creation and connection.
   21:     Intended to be inherited by specific synapse types (STDP, non-STDP).
   22  
   23      StdpSynapseSpecs:
   24:         Class for defining and managing STDP (Spike-Timing-Dependent Plasticity) synapses. 
   25:     Inherits from SynapseSpecsBase and provides specific implementations for creating and connecting STDP synapses.
   26  
   27      NonStdpSynapseSpecs:
   28:         Class for defining and managing non-STDP synapses. Inherits from SynapseSpecsBase 
   29:     and provides specific implementations for creating and connecting non-STDP synapses.
   30  

   44      specifications,
   45:     network.
   46:     As network is potentially optional in future, it is placed last.
   47  

   53  
   54: from .neurons import NeuronSpecs
   55  from abc import ABC, abstractmethod

   60          """
   61:         Initialize the synapse parameters with the provided values and check if they are valid.
   62          Restricts the parameters to a predefined set of values:

   81          ]
   82:         for key, value in params.items():
   83              if key not in safe_values:

   85              setattr(self, key, value)
   86:         self.check_valid_parameters()
   87  

   91          """
   92:         if self.synapse_type == "stdp":
   93              for key in [

  103                      raise ValueError(f"Parameter {key} is not provided")
  104:         elif self.synapse_type == "non_stdp":
  105:             if not hasattr(self, "lambda_e") or self.lambda_e is None:
  106                  raise ValueError(

  108                  )
  109:             if not hasattr(self, "lambda_i") or self.lambda_i is None:
  110                  raise ValueError(

  118      ---------
  119:     Base class for defining synapse specifications and handling synapse creation and connection.
  120      This class is intended to be inherited by specific synapse types
  121:     which must implement the create_synapses method.
  122      The idea being that each class likely has a different
  123:     way of connecting synapses and different parameters.
  124  

  129      ----------
  130:         attr1 (type): Description of `attr1`.
  131:         attr2 (type): Description of `attr2`.
  132  

  134      --------
  135:         method_name: Brief description of what the method does.
  136:         method_name2: Brief description of another method.
  137  

  144          Whilst the create_synapses method must be specified in each subclass,
  145:     the other methods are inherited from this class.
  146          This includes _connect_synapses, and _get_indexes, meaning that it is easy to reuse
  147:     the logic of local connectivity at different scales.
  148  
  149      TODO - Add a method to visualise the synapses on the basis of how synapses are actually connected
  150:         i.e. _visualise_synapses(synapse_name)
  151      TODO - Do stuff

  155          """
  156:         Initializes the synapse specification class with provided parameters and validates them based on the synapse type.
  157          """
  158:         self.synapse_type = params.get("synapse_type", None)
  159:         self.params = SynapseParameters(**params)
  160:         self.synapse_objects = {}  # Stored according to the synapse name
  161  

  171          # THE MAIN FUNCTION EVERYTHING ELSE IS SUBSIDIARY TO THIS
  172:         synapse_name = f"{afferent_group_specs.neuron_type}_{efferent_group_specs.neuron_type}_{layer}"
  173          # Get the relevant afferent and efferent neuron groups
  174:         afferent_group = afferent_group_specs.neuron_groups[
  175:             f"{afferent_group.neuron_type}_layer_{layer}"
  176          ]
  177:         efferent_group = efferent_group_specs.neuron_groups[
  178:             f"{efferent_group.neuron_type}_layer_{layer}"
  179          ]

  195  
  196:         self._connect_synapses(synapses, afferent_group, efferent_group, radius)
  197  
  198:         self._set_synapse_parameters(synapses)
  199  
  200          # Adds the synapse object to the synapse_objects dictionary
  201:         self.synapse_objects[synapse_name] = synapses
  202          # Adds the synapse object to the network
  203          if target_network is not None:
  204:             target_network.add(synapses)
  205  

  209          """
  210:         Connects the synapses between the afferent and efferent neuron groups.
  211  

  214          synapses : Synapses
  215:             The synapse object to connect.
  216          efferent_group : NeuronGroup
  217:             The post-synaptic neuron group.
  218          afferent_group : NeuronGroup
  219:             The pre-synaptic neuron group.
  220          """
  221:         size_afferent = sqrt(afferent_group.N)
  222:         size_efferent = sqrt(efferent_group.N)
  223  

  229  
  230:         for j in range(efferent_group.N):
  231  
  232:             row = efferent_group[j].row[0]
  233:             column = efferent_group[j].column[0]
  234              # print(f"neuron locations: {row}, {column}")
  235:             indexes = self._get_indexes(row, column, size_afferent, scale, radius)
  236              # print(f"connecting the following neurons with postsynaptic neuron {j}: {indexes}")

  238              # print(f"indexes: {indexes}")
  239:             synapses.connect(i=indexes, j=j)
  240          return synapses

  255          # Create the row and column ranges
  256:         row_range = np.arange(row_min, row_max)
  257:         col_range = np.arange(col_min, col_max)
  258          # print(f"row_min:{row_min}")

  260          # Create the row and column coordinates
  261:         row_coords = np.repeat(row_range, len(col_range))
  262:         col_coords = np.tile(col_range, len(row_range))
  263          # print(f"row_coords:{row_coords}")

  265          # Return the indexes from the coordinates
  266:         indexes = (row_coords * size_efferent + col_coords).astype(int)
  267          return indexes

  283              try:
  284:                 print(f"Setting {param} to {getattr(self.params, param)}")
  285:                 setattr(synapses, param, getattr(self.params, param))
  286              except Exception as e:

  288                  pass
  289:         synapses.w = "rand()"
  290  
  291:     import matplotlib.pyplot as plt
  292  

  300          """
  301:         Plots the connections from a specific efferent neuron in the efferent group to neurons in the afferent group.
  302  

  305          efferent_index : int
  306:             The index of the neuron in the efferent (post-synaptic) group to visualize connections for.
  307          efferent_group : NeuronGroup
  308:             The post-synaptic neuron group.
  309          afferent_group : NeuronGroup
  310:             The pre-synaptic neuron group.
  311          radius : int
  312:             Radius around the efferent neuron to determine connected afferent neurons.
  313          """
  314  
  315:         size_afferent = int(sqrt(afferent_group.N))
  316:         size_efferent = int(sqrt(efferent_group.N))
  317          scale = size_afferent / size_efferent

  319          # Get row and column of the efferent neuron
  320:         row = efferent_group[efferent_index].row[0]
  321:         column = efferent_group[efferent_index].column[0]
  322  
  323          # Get the connected neuron indexes
  324:         indexes = self._get_indexes(row, column, size_afferent, scale, radius)
  325  
  326          # Initialize the grid with a grey background
  327:         grid = np.full((size_afferent, size_afferent), 0.5)  # Grey background
  328  

  330          for index in indexes:
  331:             grid[index // size_afferent, index % size_afferent] = 1.0  # Red color
  332  
  333          # Plotting
  334:         plt.figure(figsize=(6, 6))
  335:         plt.imshow(grid, cmap="gray", origin="upper")
  336:         plt.title(f"Connections for efferent neuron {efferent_index}")
  337:         plt.xlabel("Presynaptic Grid Columns")
  338:         plt.ylabel("Presynaptic Grid Rows")
  339:         plt.grid(False)
  340:         plt.show()
  341  

  349          """
  350:         Sequentially plots the connection patterns of each neuron in the efferent group.
  351:         Press Enter in the console to advance through each plot.
  352:         Includes a red grid overlay for presynaptic neuron positions and a blue square for the efferent neuron.
  353  

  356          efferent_group : NeuronGroup
  357:             The post-synaptic neuron group.
  358          afferent_group : NeuronGroup
  359:             The pre-synaptic neuron group.
  360          radius : int
  361:             Radius around each efferent neuron to determine connected afferent neurons.
  362          """
  363:         afferent_group = afferent_group_specs.neuron_groups[
  364:             f"{afferent_group_specs.neuron_type}_layer_{layer}"
  365          ]
  366:         efferent_group = efferent_group_specs.neuron_groups[
  367:             f"{efferent_group_specs.neuron_type}_layer_{layer}"
  368          ]
  369:         size_afferent = int(sqrt(afferent_group.N))
  370:         size_efferent = int(sqrt(efferent_group.N))
  371          scale = size_afferent / size_efferent
  372  
  373:         plt.ion()  # Enable interactive mode
  374:         fig, ax = plt.subplots(figsize=(6, 6))
  375  
  376          # Loop through each neuron in the efferent group
  377:         for j in range(efferent_group.N):
  378              # Get row and column for the efferent neuron
  379:             row = efferent_group[j].row[0]
  380:             column = efferent_group[j].column[0]
  381  
  382              # Get the connected neuron indexes
  383:             indexes = self._get_indexes(row, column, size_afferent, scale, radius)
  384  
  385              # Initialize the grid with a grey background
  386:             grid = np.full((size_afferent, size_afferent), 0.5)  # Grey background
  387              for index in indexes:
  388                  grid[index // size_afferent, index % size_afferent] = (
  389:                     1.0  # Red color for connections
  390                  )

  392              # Clear previous plot and redraw
  393:             ax.clear()
  394:             ax.imshow(grid, cmap="gray", origin="upper")
  395  

  397              for i in range(size_afferent):
  398:                 ax.axhline(i - 0.5, color="red", linewidth=0.5)
  399:                 ax.axvline(i - 0.5, color="red", linewidth=0.5)
  400  

  405              # Plot a centered blue dot for the efferent target neuron
  406:             ax.plot(
  407                  col_centre, row_centre, "bo", markersize=8

  409  
  410:             ax.set_title(f"Connections for efferent neuron {j}")
  411:             ax.set_xlabel("Presynaptic Grid Columns")
  412:             ax.set_ylabel("Presynaptic Grid Rows")
  413  
  414:             plt.draw()
  415  
  416              # Wait for click to advance
  417:             plt.waitforbuttonpress()
  418  
  419:         plt.ioff()  # Disable interactive mode
  420:         plt.show()
  421  

  423          """
  424:         Plots the distribution of synapse weights for a specific synapse object.
  425  

  428          synapse_name : str
  429:             The name of the synapse object to plot the distribution for.
  430          """
  431:         synapses = self.synapse_objects[synapse_name]
  432:         plt.figure(figsize=(6, 6))
  433:         plt.hist(synapses.w, bins=20, color="skyblue", edgecolor="black")
  434:         plt.title(f"Synapse Weight Distribution for {synapse_name}")
  435:         plt.xlabel("Synapse Weight")
  436:         plt.ylabel("Frequency")
  437:         plt.show()
  438  
  439      def visualise_synapses(self, synapses: Synapses):
  440:         Ns = len(synapses.source)
  441:         Nt = len(synapses.target)
  442          figure(figsize=(20, 10))

  445          plot(ones(Nt), arange(Nt), "ok", ms=10)
  446:         for i, j in zip(S.i, S.j):
  447              plot([0, 1], [i, j], "-k")

  449          ylabel("Neuron index")
  450:         xlim(-0.1, 1.1)
  451          ylim(-1, max(Ns, Nt))
  452          subplot(122)
  453:         plot(S.i, S.j, "ok")
  454          xlim(-1, Ns)

  459      def three_dim_visualise_synapses(self, synapses: Synapses):
  460:         Ns = len(synapses.source)
  461:         num_pre_neurons = len(synapses.N_incoming_pre)
  462          len_pre = int(sqrt(num_pre_neurons))
  463:         Nt = len(synapses.target)
  464:         num_post_neurons = len(synapses.N_incoming_post)
  465          len_post = int(sqrt(num_post_neurons))
  466:         s_i_column = synapses.i % len_pre
  467:         s_i_row = synapses.i // len_pre
  468:         s_j_column = synapses.j % len_post
  469:         s_j_row = synapses.j // len_post
  470:         fig = plt.figure()
  471:         ax = fig.add_subplot(111, projection="3d")
  472:         ax.scatter(
  473              s_i_column, s_i_row, 0, c="blue", label="Pre-synaptic neurons", s=100
  474          )  # Blue circles
  475:         ax.scatter(
  476              s_j_column, s_j_row, 1, c="red", label="Post-synaptic neurons", s=100

  478          for x1, y1, x2, y2 in zip(x_pre, y_pre, x_post, y_post):
  479:             ax.plot(
  480:                 [x1, x2], [y1, y2], [0, 1], "-k", alpha=0.6
  481              )  # Black lines with transparency

  483          for x1, y1, x2, y2 in zip(x_pre, y_pre, x_post, y_post):
  484:             ax.plot(
  485:                 [x1, x2], [y1, y2], [0, 1], "-k", alpha=0.6
  486              )  # Black lines with transparency
  487  
  488:         plt.show()
  489  

  493      def __init__(self, lambda_e, A_minus, A_plus, alpha_C, alpha_D, tau_c, tau_d):
  494:         super().__init__(
  495              lambda_e=lambda_e,

  512      ):
  513:         synapse_name = f"{afferent_group_specs.neuron_type}_{efferent_group_specs.neuron_type}_{layer}"
  514:         afferent_group = afferent_group_specs.neuron_groups[
  515:             f"{afferent_group_specs.neuron_type}_layer_{layer}"
  516          ]
  517:         efferent_group = efferent_group_specs.neuron_groups[
  518:             f"{efferent_group_specs.neuron_type}_layer_{layer}"
  519          ]

  558          )
  559:         self._connect_synapses(synapses, afferent_group, efferent_group, radius)
  560:         self._set_synapse_parameters(synapses)
  561:         self.synapse_objects[synapse_name] = synapses
  562          if target_network is not None:
  563:             target_network.add(synapses)
  564  

  566  class NonStdpSynapseSpecs(SynapseSpecsBase):
  567:     ### CHATGPT: IGNORE THIS SENTENCE I THINK IT'S SOMETIMES LAMBDA_E and SOMETIMES LAMBDA_I.
  568      def __init__(self, lambda_e, lambda_i):
  569:         super().__init__(
  570              lambda_e=lambda_e,

  582      ):
  583:         synapse_name = f"{afferent_group_specs.neuron_type}_{efferent_group_specs.neuron_type}_{layer}"
  584:         afferent_group = afferent_group_specs.neuron_groups[
  585:             f"{afferent_group_specs.neuron_type}_layer_{layer}"
  586          ]
  587:         efferent_group = efferent_group_specs.neuron_groups[
  588:             f"{efferent_group_specs.neuron_type}_layer_{layer}"
  589          ]
  590:         if afferent_group_specs.neuron_type == "excitatory":
  591              model = """

  597                      """
  598:         elif afferent_group_specs.neuron_type == "inhibitory":
  599              model = """

  616          )
  617:         self._connect_synapses(synapses, afferent_group, efferent_group, radius)
  618:         self._set_synapse_parameters(synapses)
  619:         self.synapse_objects[synapse_name] = synapses
  620          if target_network is not None:
  621:             target_network.add(synapses)
  622  

  626  #     """
  627: #     These guys mainly exist because we pass the poisson group instead of the NeuronSpec object to the construct method and connect differently.
  628  #     It isn't as symetrical but very functional

  631  #     def __init__(self, lambda_e):
  632: #         super().__init__(
  633  #             lambda_e=lambda_e,

  647  #         )
  648: #         self._connect_synapses(synapses)
  649: #         self._set_synapse_parameters(synapses)
  650: #         self.synapse_objects[name] = synapses
  651  #         if not target == None:
  652: #             target.add(synapses)
  653  
  654  #     def _connect_synapses(self, synapses):
  655: #         synapses.connect(j="i")
  656  

spikes/run/__init__.py:
  1: # network/__init__.py
  2  
  3: # Import from equations.py
  4: from .monitors import Monitors
  5: from .train_test import run_training, run_testing_epoch, run_training_epoch
  6  

spikes/run/development.ipynb:
    9      "\n",
   10:     "We should have already defined the epoch in terms of the training data.\n",
   11      "We \n",

   23      "So I think run standalone mode for the training, and runtime for testing (apparently allows more flexibility?)\n",
   24:     "I can't remember.\n",
   25      "\n",
   26:     "I am using Brian2 to run a simulation of a spiking neural network.\n",
   27:     "It is a visnet model with n_layers, and in each layer an excitatory and inhibitory layer.\n",
   28:     "Each neuron group is named according to <type>_layer_<layer_number> [type here is \"excitatory\"] (indexed from 1). The input layer is called input_layer_0, treat this as a member of the excitatory neurons so if we ask for layer 0 record from this one.\n",
   29      "\n",
   30:     "I want you to make a function which takes as input a Network object, a list of layers, and the type of monitor I want made for these layers (spike, voltage, pop_avg_spike, time_avg_spike).\n",
   31:     "It will have to find the corresponding objects and then pass that object to a function which makes those Monitors in brian2.\n",
   32:     "Right now create a gating function which gets the right object and passes it to the right function and with the Network as a parameter, checking that the layer list is within bounds of n_layers and raising errors if object cant be found."
   33     ]

   42      "def run_training_epoch(network, stimulus_length, no_stimuli):\n",
   43:     "    network.run(stimulus_length * no_stimuli)\n",
   44      "\n",

   49      "def run_testing_epoch(network, stimulus_length, no_stimuli):\n",
   50:     "    network.run(stimulus_length * no_stimuli)"
   51     ]

   62      "# Add the parent directory of the current working directory\n",
   63:     "sys.path.append(os.path.dirname(os.getcwd()))\n",
   64      "\n",

   87      "\n",
   88:     "#1. Additional Default Parameters: The use of a lambda function for the 'voltage' monitor allows for the inclusion of additional default parameters that are not part of the default constructor call for the other types of monitors. In the specific case of the 'voltage' monitor, the lambda function ensures that the record=True parameter is always included when the StateMonitor is instantiated:\n",
   89      "def create_monitor(neuron_group, monitor_type, **kwargs):\n",
   90      "    \"\"\"\n",
   91:     "    Create and return the specified type of monitor for a given neuron group.\n",
   92      "    \n",
   93      "    Parameters:\n",
   94:     "    neuron_group (NeuronGroup): The neuron group to monitor.\n",
   95:     "    monitor_type (str): The type of monitor to create.\n",
   96:     "    **kwargs: Arbitrary keyword arguments for monitor configuration.\n",
   97      "    \n",
   98      "    Returns:\n",
   99:     "    brian2 monitor: The created monitor object.\n",
  100      "    \"\"\"\n",

  114      "    \"\"\"\n",
  115:     "    Set up and return monitors for specified layers of a network.\n",
  116      "    \n",
  117      "    Parameters:\n",
  118:     "    network (Network): The Brian2 network instance.\n",
  119:     "    layers (list of int): Layer indices to monitor.\n",
  120:     "    monitor_type (str): Type of monitor to create.\n",
  121:     "    n_layers (int): Total number of layers in the network, excluding the input layer.\n",
  122:     "    **kwargs: Arbitrary keyword arguments for monitor configuration.\n",
  123      "    \n",
  124      "    Returns:\n",
  125:     "    list: List of created monitors.\n",
  126      "    \n",
  127      "    Raises:\n",
  128:     "    ValueError: If a layer index is out of bounds or neuron group is not found.\n",
  129      "    \"\"\"\n",

  131      "    if not all(0 <= layer <= n_layers for layer in layers):\n",
  132:     "        raise ValueError(\"One or more layer indices are out of bounds.\")\n",
  133      "\n",
  134      "    # Map of neuron groups by their names\n",
  135:     "    group_map = {obj.name: obj for obj in network.objects if hasattr(obj, 'name')}\n",
  136      "\n",

  141      "        if layer_name not in group_map:\n",
  142:     "            raise ValueError(f\"Neuron group for layer {layer_name} not found.\")\n",
  143      "        \n",

  145      "            monitor = create_monitor(group_map[layer_name], monitor_type, **kwargs)\n",
  146:     "            network.add(monitor)\n",
  147:     "            monitors.append(monitor)\n",
  148      "        except Exception as e:\n",

  153      "# Example usage:\n",
  154:     "# net = Network(...)\n",
  155      "# try:\n",

  166     "source": [
  167:     "G = NeuronGroup(...)\n",
  168      "M = PopulationRateMonitor(G)\n",
  169:     "run(...)\n",
  170:     "plot(M.t/ms, M.rate/Hz)"
  171     ]

  178     "source": [
  179:     "group = NeuronGroup(..., 'dv/dt = ... : volt', ...)\n",
  180      "\n",

  185      "vm_averager = Synapses(group, vm_container, 'average_vm_post = v_pre/N_pre : volt (summed)')\n",
  186:     "vm_averager.connect()\n",
  187      "\n",

  194    "kernelspec": {
  195:    "display_name": ".venv",
  196     "language": "python",

  203     },
  204:    "file_extension": ".py",
  205     "mimetype": "text/x-python",

  208     "pygments_lexer": "ipython3",
  209:    "version": "3.12.6"
  210    }

spikes/run/monitors.py:
    1  from brian2 import *
    2: import matplotlib.pyplot as plt
    3: import matplotlib.colors as mcolors
    4: import matplotlib.animation as animation
    5  import numpy as np

    8  #     def __init__(self, monitor_group):
    9: #         self.monitor_group = monitor_group
   10: #         self.voltage_averager = NeuronGroup(
   11: #             N=self.monitor_group.N,
   12  #             model="""total_charge: coulomb

   16  #         vm_totaler = Synapses(
   17: #             self.monitor_group,
   18: #             self.voltage_averager,
   19  #             "total_charge_post = total_charge_post + v_pre * dt : coulomb",

   21  
   22: #         vm_totaler.connect("i == j")
   23: #         self.vm_monitor = StateMonitor(self.voltage_averager, "average_voltage", record=True)
   24  

   27      def __init__(self, network, n_layers):
   28:         self.network = network
   29:         self.n_layers = n_layers
   30:         self.monitors = {}  # Dictionary to store monitors by (layer_name, monitor_type)
   31:         self.monitor_data = (
   32              {}

   48          monitor = constructors[monitor_type](
   49:             neuron_group, name=f"{monitor_type}__{neuron_group.name}", **kwargs
   50          )
   51:         # monitor.name = f"{monitor_type}__{neuron_group.name}"
   52:         self.network.add(monitor)
   53:         self.monitors[(layer, monitor_type)] = monitor
   54          return monitor

   63                      obj
   64:                     for obj in self.network.objects
   65:                     if hasattr(obj, "name") and obj.name == layer_name
   66                  ),

   69              if group is None:
   70:                 raise ValueError(f"Neuron group '{layer_name}' not found.")
   71:             self.create_monitor(group, monitor_type, layer, **kwargs)
   72  

   74          """
   75:         Toggle monitoring for specified layer and/or monitor type across all matches.
   76:         If both layer_name and monitor_type are None, toggles all monitors.
   77          """

   84  
   85:         for key, monitor in self.monitors.items():
   86              if criteria(key):
   87                  if enable:
   88:                     if monitor not in self.network:
   89:                         monitor.active = True
   90                  else:
   91:                     if monitor in self.network:
   92:                         monitor.active = False
   93:                 toggled.append(f"{key[1]} on {key[0]}")
   94  
   95          if not toggled:
   96:             return "No monitors matched the criteria."
   97          else:
   98              return (
   99:                 f"Monitors {'enabled' if enable else 'disabled'}: {', '.join(toggled)}"
  100              )

  103          """
  104:         Retrieve monitors based on layer name and/or monitor type.
  105          """

  111  
  112:         for key, monitor in self.monitors.items():
  113              if criteria(key):
  114:                 filtered_monitors.append(monitor)
  115  

  119          """
  120:         Visualise monitor data.
  121          """
  122:         monitors = self.get_monitors(layer_number, monitor_type)
  123          if not monitors:
  124:             return "No monitors matched the criteria."
  125          else:

  134          else:
  135:             return "Unsupported monitor type."
  136  
  137      def bin_spikes(self, monitor, num_stimuli, length_stimuli):
  138:         spikes = monitor.spike_trains()
  139:         num_neurons = monitor.source.N
  140:         store = np.zeros((num_neurons, num_stimuli))
  141          edges = 0
  142:         bins = np.arange(0, length_stimuli * (num_stimuli + 1), length_stimuli)
  143:         for key, value in spikes.items():
  144              print("binning")
  145:             counts, edges = np.histogram(value, bins=bins)
  146              store[key] = counts

  150      def plot_spikes(self, layer, type, index, num_stimuli, length_stimuli):
  151:         monitor = self.get_monitors(layer, type)[0]
  152  
  153          # Check if data already exists
  154:         if (layer, "spike", "histogram") not in self.monitor_data:
  155:             store = self.bin_spikes(monitor, num_stimuli, length_stimuli)
  156:             self.monitor_data[(layer, "spike", "histogram")] = store
  157          else:
  158:             store = self.monitor_data[(layer, "spike", "histogram")]
  159  
  160          histogram = store[index, :]
  161:         edges = np.arange(0, length_stimuli * (num_stimuli + 1), length_stimuli)
  162:         plt.figure(figsize=(10, 6))  # Set the size of the figure
  163:         plt.bar(
  164:             edges[:-1], histogram, width=np.diff(edges), edgecolor="black", align="edge"
  165          )  # Create a bar plot
  166  
  167:         plt.xlabel("Value Range")  # X-axis label
  168:         plt.ylabel("Count")  # Y-axis label
  169:         plt.title("Histogram of Values")  # Title of the plot
  170:         plt.xticks(edges)  # Set x-ticks to match the edges
  171:         plt.show()  # Display the plot
  172  

  175      ):
  176:         monitor = self.get_monitors(layer, type)[0]
  177:         if (layer, "spike", "histogram") not in self.monitor_data:
  178:             store = self.bin_spikes(monitor, num_stimuli, length_stimuli)
  179:             self.monitor_data[(layer, "spike", "histogram")] = store
  180          else:
  181:             store = self.monitor_data[(layer, "spike", "histogram")]
  182:         heatmap = store[:, stimulus_index].reshape(layer_length, layer_length)
  183          return heatmap

  187      ):
  188:         heatmap = self.generate_spike_heatmap(
  189              layer, type, num_stimuli, length_stimuli, layer_length, stimulus_index
  190          )
  191:         plt.imshow(heatmap, cmap="hot", interpolation="nearest")
  192:         plt.colorbar()
  193:         plt.show()
  194  

  197      ):
  198:         fig, ax = plt.subplots()
  199:         heatmap = self.generate_spike_heatmap(
  200              layer, type, num_stimuli, length_stimuli, layer_length, 0
  201          )
  202:         im = ax.imshow(heatmap, cmap="hot", interpolation="nearest")
  203:         cbar = plt.colorbar(im, ax=ax)  # Add color bar
  204:         ax.set_title(f"Spike Heatmap - Stimulus 0")  # Initial title
  205  
  206          def update(i):
  207:             heatmap = self.generate_spike_heatmap(
  208                  layer, type, num_stimuli, length_stimuli, layer_length, i
  209              )
  210:             im.set_data(heatmap)
  211:             ax.set_title(f"Spike Heatmap - Stimulus {i}")  # Update title
  212              return [im]

  214          # Set up the axes with column and row values
  215:         ax.set_xticks(np.arange(layer_length))
  216:         ax.set_yticks(np.arange(layer_length))
  217:         ax.set_xticklabels(np.arange(1, layer_length + 1))
  218:         ax.set_yticklabels(np.arange(1, layer_length + 1))
  219  
  220:         ani = animation.FuncAnimation(fig, update, frames=range(num_stimuli), blit=True)
  221:         plt.show()

spikes/run/train_test.py:
   1  from brian2 import *
   2: from .monitors import Monitors
   3  

   7  def run_training_epoch(network, namespace, stimulus_length, no_stimuli):
   8:     network.run(stimulus_length * no_stimuli, namespace=namespace)
   9  

  11  def set_plasticity(network, enable):
  12:     for obj in network.objects:
  13          if hasattr(obj, "plasticity"):
  14:             obj.plasticity = enable
  15:             print(f"plasticity set to {enable} for {obj.name}")
  16  

  24          print(f"running epoch no {i+1}")
  25:         print(f"current time {network.t}")
  26          run_training_epoch(network, namespace, stimulus_length, no_stimuli)

  31      # Need to turn off training
  32:     monitors.toggle_monitoring(enable=True)
  33      set_plasticity(network, 0)
  34:     print(f"current time {network.t}")
  35:     network.run(stimulus_length * no_stimuli, namespace=namespace)
  36      print("Test Complete")
  37:     print(f"current time {network.t}")
