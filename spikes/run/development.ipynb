{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what am I looking to do?\n",
    "Train an epoch:\n",
    "\n",
    "We should have already defined the epoch in terms of the training data.\n",
    "We \n",
    "\n",
    "Train several epochs\n",
    "Test \n",
    "monitor during test\n",
    "graph results\n",
    "information theory\n",
    "\n",
    "When we run the network we wnat\n",
    "\n",
    "Make sure to delete data after the run\n",
    "\n",
    "So I think run standalone mode for the training, and runtime for testing (apparently allows more flexibility?)\n",
    "I can't remember.\n",
    "\n",
    "I am using Brian2 to run a simulation of a spiking neural network.\n",
    "It is a visnet model with n_layers, and in each layer an excitatory and inhibitory layer.\n",
    "Each neuron group is named according to <type>_layer_<layer_number> [type here is \"excitatory\"] (indexed from 1). The input layer is called input_layer_0, treat this as a member of the excitatory neurons so if we ask for layer 0 record from this one.\n",
    "\n",
    "I want you to make a function which takes as input a Network object, a list of layers, and the type of monitor I want made for these layers (spike, voltage, pop_avg_spike, time_avg_spike).\n",
    "It will have to find the corresponding objects and then pass that object to a function which makes those Monitors in brian2.\n",
    "Right now create a gating function which gets the right object and passes it to the right function and with the Network as a parameter, checking that the layer list is within bounds of n_layers and raising errors if object cant be found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brian2 import *\n",
    "def run_training_epoch(network, stimulus_length, no_stimuli):\n",
    "    network.run(stimulus_length * no_stimuli)\n",
    "\n",
    "def run_training(network, stimulus_length, no_stimuli, no_epochs):\n",
    "    for i in range(no_epochs):\n",
    "        run_training_epoch(network, stimulus_length, no_stimuli)\n",
    "\n",
    "def run_testing_epoch(network, stimulus_length, no_stimuli):\n",
    "    network.run(stimulus_length * no_stimuli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory of the current working directory\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "\n",
    "from brian2 import *\n",
    "from input import *\n",
    "from network import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brian2 import Network, SpikeMonitor, StateMonitor, PopulationRateMonitor\n",
    "\n",
    "#1. Additional Default Parameters: The use of a lambda function for the 'voltage' monitor allows for the inclusion of additional default parameters that are not part of the default constructor call for the other types of monitors. In the specific case of the 'voltage' monitor, the lambda function ensures that the record=True parameter is always included when the StateMonitor is instantiated:\n",
    "def create_monitor(neuron_group, monitor_type, **kwargs):\n",
    "    \"\"\"\n",
    "    Create and return the specified type of monitor for a given neuron group.\n",
    "    \n",
    "    Parameters:\n",
    "    neuron_group (NeuronGroup): The neuron group to monitor.\n",
    "    monitor_type (str): The type of monitor to create.\n",
    "    **kwargs: Arbitrary keyword arguments for monitor configuration.\n",
    "    \n",
    "    Returns:\n",
    "    brian2 monitor: The created monitor object.\n",
    "    \"\"\"\n",
    "    monitor_factory = {\n",
    "        'spike': SpikeMonitor,\n",
    "        'voltage': lambda group, **kw: StateMonitor(group, 'v', record=True, **kw),\n",
    "        'pop_avg_spike': PopulationRateMonitor,\n",
    "        'time_avg_spike': PopulationRateMonitor\n",
    "    }\n",
    "    \n",
    "    if monitor_type in monitor_factory:\n",
    "        return monitor_factory[monitor_type](neuron_group, **kwargs)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported monitor type: {monitor_type}\")\n",
    "\n",
    "def setup_monitors(network, layers, monitor_type, n_layers, **kwargs):\n",
    "    \"\"\"\n",
    "    Set up and return monitors for specified layers of a network.\n",
    "    \n",
    "    Parameters:\n",
    "    network (Network): The Brian2 network instance.\n",
    "    layers (list of int): Layer indices to monitor.\n",
    "    monitor_type (str): Type of monitor to create.\n",
    "    n_layers (int): Total number of layers in the network, excluding the input layer.\n",
    "    **kwargs: Arbitrary keyword arguments for monitor configuration.\n",
    "    \n",
    "    Returns:\n",
    "    list: List of created monitors.\n",
    "    \n",
    "    Raises:\n",
    "    ValueError: If a layer index is out of bounds or neuron group is not found.\n",
    "    \"\"\"\n",
    "    # Validate layer indices\n",
    "    if not all(0 <= layer <= n_layers for layer in layers):\n",
    "        raise ValueError(\"One or more layer indices are out of bounds.\")\n",
    "\n",
    "    # Map of neuron groups by their names\n",
    "    group_map = {obj.name: obj for obj in network.objects if hasattr(obj, 'name')}\n",
    "\n",
    "    monitors = []\n",
    "    for layer in layers:\n",
    "        layer_name = f\"excitatory_layer_{layer}\" if layer != 0 else \"input_layer_0\"\n",
    "        \n",
    "        if layer_name not in group_map:\n",
    "            raise ValueError(f\"Neuron group for layer {layer_name} not found.\")\n",
    "        \n",
    "        try:\n",
    "            monitor = create_monitor(group_map[layer_name], monitor_type, **kwargs)\n",
    "            network.add(monitor)\n",
    "            monitors.append(monitor)\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Error creating monitor for {layer_name}: {str(e)}\")\n",
    "    \n",
    "    return monitors\n",
    "\n",
    "# Example usage:\n",
    "# net = Network(...)\n",
    "# try:\n",
    "#     monitors = setup_monitors(net, [0, 1, 2], 'voltage', n_layers=4, record=True)\n",
    "# except ValueError as e:\n",
    "#     print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = NeuronGroup(...)\n",
    "M = PopulationRateMonitor(G)\n",
    "run(...)\n",
    "plot(M.t/ms, M.rate/Hz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = NeuronGroup(..., 'dv/dt = ... : volt', ...)\n",
    "\n",
    "# Dummy group to store the average membrane potential at every time step\n",
    "vm_container = NeuronGroup(1, 'average_vm : volt')\n",
    "\n",
    "# Synapses averaging the membrane potential of all neurons in group\n",
    "vm_averager = Synapses(group, vm_container, 'average_vm_post = v_pre/N_pre : volt (summed)')\n",
    "vm_averager.connect()\n",
    "\n",
    "# Monitor recording the average membrane potential\n",
    "vm_monitor = StateMonitor(vm_container, 'average_vm', record=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [ 9 10 11 12]\n",
      " [13 14 15 16]]\n",
      "[ 1 17  2 18  3 19  4 20  5 21  6 22  7 23  8 24  9 25 10 26 11 27 12 28\n",
      " 13 29 14 30 15 31 16 32 33 49 34 50 35 51 36 52 37 53 38 54 39 55 40 56\n",
      " 41 57 42 58 43 59 44 60 45 61 46 62 47 63 48 64 65 81 66 82 67 83 68 84\n",
      " 69 85 70 86 71 87 72 88 73 89 74 90 75 91 76 92 77 93 78 94 79 95 80 96]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create a dummy np.array where its dimensions are images x height x width x num_filters (3x4x4x2)\n",
    "images = np.zeros((3, 4, 4, 2), dtype=int)\n",
    "\n",
    "# Fill the array with the desired pattern\n",
    "value = 1\n",
    "for img in range(images.shape[0]):\n",
    "    for filter in range(images.shape[3]):\n",
    "        for row in range(images.shape[1]):\n",
    "            for col in range(images.shape[2]):\n",
    "                images[img, row, col, filter] = value\n",
    "                value += 1\n",
    "\n",
    "print(images[0, :, :, 0])\n",
    "print(images.flatten())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (5,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m      2\u001b[0m data \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m----> 3\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mideas\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m      4\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      5\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m29\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (5,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "import json\n",
    "data = {}\n",
    "data['ideas'] = np.array([np.array([]), np.array([1,2,3]),np.array([1,2,3]), np.array([1,2,3]), np.array([1,2,3])]).tolist()\n",
    "data['name'] = 'test'\n",
    "data['age'] = 29\n",
    "\n",
    "with open('data.json', 'w') as f:\n",
    "    json.dump(data, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
